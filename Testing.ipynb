{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary keys being frequencies, values are np arrays of `Nc x Ns x Nt` (channels x samples x trials). \n",
    "\n",
    "First import the data from one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_7 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\7hz\\7hz_LED.txt\",\"r\")\n",
    "data_file_7 = data_file_7.read().split(', ')\n",
    "for i, v in enumerate(data_file_7):\n",
    "    if '[' in v:\n",
    "        data_file_7[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_7[i] = v.replace(']\\n','')\n",
    "\n",
    "values_7 = [int(i) for i in data_file_7]\n",
    "\n",
    "data_file_10 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\10hz\\10hz_LED.txt\", \"r\")\n",
    "data_file_10 = data_file_10.read().split(', ')\n",
    "for i, v in enumerate(data_file_10):\n",
    "    if '[' in v:\n",
    "        data_file_10[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_10[i] = v.replace(']\\n','')\n",
    "\n",
    "values_10 = [int(i) for i in data_file_10]\n",
    "\n",
    "data_file_12 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\12hz\\12hz_LED.txt\", \"r\")\n",
    "data_file_12 = data_file_12.read().split(', ')\n",
    "for i, v in enumerate(data_file_12):\n",
    "    if '[' in v:\n",
    "        data_file_12[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_12[i] = v.replace(']\\n','')\n",
    "\n",
    "values_12 = [int(i) for i in data_file_12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passband the values\n",
    "\n",
    "Elliptical 10th order bandpass filter with corner frequencies at (4, 28)Hz,\n",
    "0.2dB passband ripple and 80dB stopband atten\n",
    "\n",
    "i.e the same filter that will happen on the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fs = 256\n",
    "filt_ord = 10\n",
    "pb_rip = 0.2\n",
    "sb_atten = 80\n",
    "\n",
    "fc_lo = 4 # pass band lower freq\n",
    "fc_hi = 28 # pass band upp freq \n",
    "wc_lo = fc_lo/(fs*0.5)\n",
    "wc_hi = fc_hi/(fs*0.5)\n",
    "\n",
    "sos_ellip = signal.ellip(filt_ord, pb_rip, sb_atten, (wc_lo, wc_hi), btype='bandpass', output='sos')\n",
    "\n",
    "filtered = signal.sosfilt(sos_ellip, values_10[::2])\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [\n",
    "        [\n",
    "            5.18442631e-04,\n",
    "            5.91022291e-04,\n",
    "            5.18442631e-04,\n",
    "            1.00000000e00,\n",
    "            -1.58700686e00,\n",
    "            6.47826110e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -6.71721317e-01,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.56164716e00,\n",
    "            7.42956116e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.19862825e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.53434369e00,\n",
    "            8.53024717e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.36462221e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52074686e00,\n",
    "            9.31086238e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.41821305e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52570664e00,\n",
    "            9.80264626e-01,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "filtered_new = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_10[::2])\n",
    "\n",
    "filtered = filtered[256:]\n",
    "filtered_board = filtered_new[256:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)\n",
    "t = np.linspace(0, 29, len(values_10[512::2]), False)\n",
    "\n",
    "ax1.plot(t, values_10[512::2]-np.mean(values_10[512::2]))\n",
    "ax1.set_title('Unfiltered')\n",
    "\n",
    "ax2.plot(t, filtered)\n",
    "ax2.set_title('Filtered scipy')\n",
    "\n",
    "ax3.plot(t, filtered_board - np.mean(filtered_board))\n",
    "ax3.set_title('Filtered board')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCCA, MsetCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "freqs =[7,10,12]\n",
    "downsample_avg_size = 2\n",
    "\n",
    "filtered_10 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_10)\n",
    "filtered_10 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_10)]*downsample_avg_size)])[256:]\n",
    "\n",
    "filtered_12 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_12)\n",
    "filtered_12 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_12)]*downsample_avg_size)])[256:]\n",
    "\n",
    "filtered_7 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_7)\n",
    "filtered_7 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_7)]*downsample_avg_size)])[256:]\n",
    "\n",
    "print(filtered_7.shape)\n",
    "print(filtered_10.shape)\n",
    "print(filtered_12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_train = 4\n",
    "fs = 256\n",
    "\n",
    "# synth_7 = (synth_X(7,1,256,4).T).reshape(1,fs,4)\n",
    "\n",
    "train7_reshape = np.array(filtered_7[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train7 = train7_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train10_reshape = np.array(filtered_10[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train10 = train10_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train12_reshape = np.array(filtered_12[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train12 = train12_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train = np.array([train7, train10, train12])\n",
    "\n",
    "test7 = filtered_7[fs*number_of_train:]\n",
    "test10 = filtered_10[fs*number_of_train:]\n",
    "test12 = filtered_12[fs*number_of_train:]\n",
    "\n",
    "print(train7.shape)\n",
    "print(len(test7)/fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "\n",
    "gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "\n",
    "mset_cca = MsetCCA_SSVEP(freqs)\n",
    "\n",
    "gcca.fit(train)\n",
    "mset_cca.fit(train)\n",
    "\n",
    "gcca_7 = []\n",
    "mset_7 =[]\n",
    "\n",
    "for begin in range(0, int(len(test7)/256)):\n",
    "    gcca_decode = gcca.classify(test7[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_7.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test7[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_7.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(gcca_7.count(7)/len(gcca_7), '\\n', mset_7.count(7)/len(mset_7))\n",
    "\n",
    "gcca_10 = []\n",
    "mset_10 =[]\n",
    "\n",
    "for begin in range(0, int(len(test10)/256)):\n",
    "    gcca_decode = gcca.classify(test10[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_10.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test10[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_10.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(gcca_10.count(10)/len(gcca_10), '\\n', mset_10.count(10)/len(mset_10))\n",
    "\n",
    "gcca_12 = []\n",
    "mset_12 =[]\n",
    "\n",
    "for begin in range(0, int(len(test12)/256)):\n",
    "    gcca_decode = gcca.classify(test12[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_12.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test12[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_12.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(gcca_12.count(12)/len(gcca_12), '\\n', mset_12.count(12)/len(mset_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using online dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "from eeg_lib.utils import standardise\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\online_dataset\\data\\subject1.csv\",sep=';')\n",
    "s1_8_57 = standardise(df['F1'].to_numpy())\n",
    "s1_10 = standardise(df['F2'].to_numpy())\n",
    "s1_12 = standardise(df['F3'].to_numpy())\n",
    "s1_15 = standardise(df['F4'].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs =[8.57,10,12,15]\n",
    "fs = 256\n",
    "number_of_train = 4\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [\n",
    "        [\n",
    "            5.18442631e-04,\n",
    "            5.91022291e-04,\n",
    "            5.18442631e-04,\n",
    "            1.00000000e00,\n",
    "            -1.58700686e00,\n",
    "            6.47826110e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -6.71721317e-01,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.56164716e00,\n",
    "            7.42956116e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.19862825e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.53434369e00,\n",
    "            8.53024717e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.36462221e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52074686e00,\n",
    "            9.31086238e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.41821305e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52570664e00,\n",
    "            9.80264626e-01,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "filtered_857 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_8_57)\n",
    "filtered_10 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_10)\n",
    "filtered_12 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_12)\n",
    "filtered_15 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_15)\n",
    "\n",
    "# filtered_857 = s1_8_57\n",
    "# filtered_10 = s1_10\n",
    "# filtered_12 = s1_12\n",
    "# filtered_15 = s1_15\n",
    "\n",
    "\n",
    "train857_reshape = np.array(filtered_857[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train857 = train857_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train10_reshape = np.array(filtered_10[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train10 = train10_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train12_reshape = np.array(filtered_12[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train12 = train12_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train15_reshape = np.array(filtered_15[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train15 = train15_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "\n",
    "# train857 = np.array(filtered_857[len(filtered_857)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train10 = np.array(filtered_10[len(filtered_10)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train12 = np.array(filtered_12[len(filtered_12)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train15 = np.array(filtered_15[len(filtered_15)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "\n",
    "train = np.array([train857, train10, train12, train15])\n",
    "\n",
    "test857 = filtered_857[256*number_of_train:]\n",
    "test10= filtered_10[256*number_of_train:]\n",
    "test12 = filtered_12[256*number_of_train:]\n",
    "test15 = filtered_15[256*number_of_train:]\n",
    "\n",
    "# test857 = filtered_857[:len(filtered_857)-256*number_of_train]\n",
    "# test10= filtered_10[:len(filtered_10)-256*number_of_train]\n",
    "# test12 = filtered_12[:len(filtered_12)-256*number_of_train]\n",
    "# test15 = filtered_15[:len(filtered_15)-256*number_of_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "\n",
    "gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "\n",
    "mset_cca = MsetCCA_SSVEP(freqs)\n",
    "\n",
    "gcca.fit(train)\n",
    "mset_cca.fit(train)\n",
    "\n",
    "gcca_857 = []\n",
    "mset_857 =[]\n",
    "\n",
    "for begin in range(0, int(len(test857)/256)):\n",
    "    gcca_decode = gcca.classify(test857[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_857.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test857[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_857.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 8.57hz accuracy: \", gcca_857.count(7)/len(gcca_857), '\\nMset 8.57hz accuracy: ', mset_857.count(7)/len(mset_857))\n",
    "\n",
    "gcca_10 = []\n",
    "mset_10 =[]\n",
    "\n",
    "for begin in range(0, int(len(test10)/256)):\n",
    "    gcca_decode = gcca.classify(test10[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_10.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test10[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_10.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 10hz accuracy: \",gcca_10.count(10)/len(gcca_10), '\\nMset 10hz accuracy: ', mset_10.count(10)/len(mset_10))\n",
    "\n",
    "gcca_12 = []\n",
    "mset_12 =[]\n",
    "\n",
    "for begin in range(0, int(len(test12)/256)):\n",
    "    gcca_decode = gcca.classify(test12[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_12.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test12[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_12.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 12hz accuracy: \",gcca_12.count(12)/len(gcca_12), '\\nMset 12hz accuracy: ', mset_12.count(12)/len(mset_12))\n",
    "\n",
    "gcca_15 = []\n",
    "mset_15 =[]\n",
    "\n",
    "for begin in range(0, int(len(test15)/256)):\n",
    "    gcca_decode = gcca.classify(test15[256*begin:256*begin+256].reshape(1,256))\n",
    "    gcca_15.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test15[256*begin:256*begin+256].reshape(1,256))\n",
    "    mset_15.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 15hz accuracy: \",gcca_15.count(15)/len(gcca_15), '\\nMset 15hz accuracy: ', mset_15.count(15)/len(mset_15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64hz over 4 second approach - own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "data_file_7 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\7hz\\7hz_LED2.txt\", \"r\")\n",
    "data_file_7 = data_file_7.read().split(', ')\n",
    "for i, v in enumerate(data_file_7):\n",
    "    if '[' in v:\n",
    "        data_file_7[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_7[i] = v.replace(']\\n','')\n",
    "\n",
    "downsample_avg_size = 1\n",
    "\n",
    "values_7 = [int(i) for i in data_file_7]\n",
    "values_7 = [sum(group) / downsample_avg_size for group in zip(*[iter(values_7)]*downsample_avg_size)]\n",
    "\n",
    "data_file_10 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\10hz\\10hz_LED2.txt\", \"r\")\n",
    "data_file_10 = data_file_10.read().split(', ')\n",
    "for i, v in enumerate(data_file_10):\n",
    "    if '[' in v:\n",
    "        data_file_10[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_10[i] = v.replace(']\\n','')\n",
    "\n",
    "values_10 = [int(i) for i in data_file_10]\n",
    "values_10 = [sum(group) / downsample_avg_size for group in zip(*[iter(values_10)]*downsample_avg_size)]\n",
    "\n",
    "data_file_12 = open(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\12hz\\12hz_LED2.txt\", \"r\")\n",
    "data_file_12 = data_file_12.read().split(', ')\n",
    "for i, v in enumerate(data_file_12):\n",
    "    if '[' in v:\n",
    "        data_file_12[i] = v.replace('[','')\n",
    "    if ']\\n' in v:\n",
    "        data_file_12[i] = v.replace(']\\n','')\n",
    "\n",
    "values_12 = [int(i) for i in data_file_12] #because sampled at 512, sos filter uses 256\n",
    "values_12 = [sum(group) / downsample_avg_size for group in zip(*[iter(values_12)]*downsample_avg_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(values_12), len(values_10),len(values_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs =[7,10,12]\n",
    "fs = 256\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [\n",
    "        [\n",
    "            5.18442631e-04,\n",
    "            5.91022291e-04,\n",
    "            5.18442631e-04,\n",
    "            1.00000000e00,\n",
    "            -1.58700686e00,\n",
    "            6.47826110e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -6.71721317e-01,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.56164716e00,\n",
    "            7.42956116e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.19862825e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.53434369e00,\n",
    "            8.53024717e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.36462221e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52074686e00,\n",
    "            9.31086238e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.41821305e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52570664e00,\n",
    "            9.80264626e-01,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "downsample_avg_size = 1\n",
    "\n",
    "# filtered_10 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_10)\n",
    "filtered_10 = values_10\n",
    "filtered_10 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_10)]*downsample_avg_size)])\n",
    "\n",
    "# filtered_12 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_12)\n",
    "filtered_12 = values_12\n",
    "filtered_12 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_12)]*downsample_avg_size)])\n",
    "\n",
    "# filtered_7 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values_7)\n",
    "filtered_7 = values_7\n",
    "filtered_7 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_7)]*downsample_avg_size)])\n",
    "\n",
    "print(filtered_7.shape)\n",
    "print(filtered_10.shape)\n",
    "print(filtered_12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_train = 8\n",
    "\n",
    "train7_reshape = np.array(filtered_7[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train7 = train7_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train10_reshape = np.array(filtered_10[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train10 = train10_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train12_reshape = np.array(filtered_12[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train12 = train12_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train = np.array([train7, train10, train12])\n",
    "test7 = filtered_7[fs*number_of_train:]\n",
    "test10= filtered_10[fs*number_of_train:]\n",
    "test12 = filtered_12[fs*number_of_train:]\n",
    "\n",
    "print(train7.shape,len(test7)/256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "\n",
    "gcca = GCCA_SSVEP(freqs, fs=512, Nh=1)\n",
    "\n",
    "mset_cca = MsetCCA_SSVEP(freqs)\n",
    "\n",
    "gcca.fit(train)\n",
    "mset_cca.fit(train)\n",
    "\n",
    "gcca_7 = []\n",
    "mset_7 =[]\n",
    "\n",
    "for begin in range(0, int(len(test7)/fs)):\n",
    "    gcca_decode = gcca.classify(test7[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_7.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test7[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_7.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 7hz accuracy: \",gcca_7.count(7)/len(gcca_7), '\\nMset 7hz accuracy: ', mset_7.count(7)/len(mset_7))\n",
    "\n",
    "gcca_10 = []\n",
    "mset_10 = []\n",
    "\n",
    "for begin in range(0, int(len(test10)/fs)):\n",
    "    gcca_decode = gcca.classify(test10[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_10.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test10[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_10.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 10hz accuracy: \",gcca_10.count(10)/len(gcca_10), '\\nMset 10hz accuracy: ', mset_10.count(10)/len(mset_10))\n",
    "\n",
    "gcca_12 = []\n",
    "mset_12 =[]\n",
    "\n",
    "for begin in range(0, int(len(test12)/fs)):\n",
    "    gcca_decode = gcca.classify(test12[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_12.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test12[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_12.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 12hz accuracy: \",gcca_12.count(12)/len(gcca_12), '\\nMset 12hz accuracy: ', mset_12.count(12)/len(mset_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 64hz over 4 second approach - online dataset\n",
    "Not enough data in one trial for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import math\n",
    "from eeg_lib.utils import standardise\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\online_dataset\\data\\subject1.csv\",sep=';')\n",
    "s1_8_57 = standardise(df['F1'].to_numpy())\n",
    "s1_10 = standardise(df['F2'].to_numpy())\n",
    "s1_12 = standardise(df['F3'].to_numpy())\n",
    "s1_15 = standardise(df['F4'].to_numpy())\n",
    "# s1_8_57 = (df['F1'].to_numpy())\n",
    "# s1_10 = (df['F2'].to_numpy())\n",
    "# s1_12 = (df['F3'].to_numpy())\n",
    "# s1_15 = (df['F4'].to_numpy())\n",
    "\n",
    "freqs =[8.57,10,12,15]\n",
    "fs = 64\n",
    "number_of_train = 2\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [\n",
    "        [\n",
    "            5.18442631e-04,\n",
    "            5.91022291e-04,\n",
    "            5.18442631e-04,\n",
    "            1.00000000e00,\n",
    "            -1.58700686e00,\n",
    "            6.47826110e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -6.71721317e-01,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.56164716e00,\n",
    "            7.42956116e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.19862825e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.53434369e00,\n",
    "            8.53024717e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.36462221e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52074686e00,\n",
    "            9.31086238e-01,\n",
    "        ],\n",
    "        [\n",
    "            1.00000000e00,\n",
    "            -1.41821305e00,\n",
    "            1.00000000e00,\n",
    "            1.00000000e00,\n",
    "            -1.52570664e00,\n",
    "            9.80264626e-01,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "\n",
    "downsample_avg_size = 4\n",
    "filtered_857 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_8_57)\n",
    "filtered_857 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_857)]*downsample_avg_size)])\n",
    "\n",
    "filtered_10 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_10)\n",
    "filtered_10 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_10)]*downsample_avg_size)])\n",
    "\n",
    "filtered_12 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_12)\n",
    "filtered_12 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_12)]*downsample_avg_size)])\n",
    "\n",
    "filtered_15 = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, s1_15)\n",
    "filtered_15 = np.array([sum(group) / downsample_avg_size for group in zip(*[iter(filtered_15)]*downsample_avg_size)])\n",
    "\n",
    "# filtered_857 = s1_8_57\n",
    "# filtered_10 = s1_10\n",
    "# filtered_12 = s1_12\n",
    "# filtered_15 = s1_15\n",
    "\n",
    "train857_reshape = np.array(filtered_857[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train857 = train857_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train10_reshape = np.array(filtered_10[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train10 = train10_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train12_reshape = np.array(filtered_12[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train12 = train12_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "train15_reshape = np.array(filtered_15[:fs*number_of_train]).reshape(number_of_train,fs)\n",
    "train15 = train15_reshape.T.reshape(1,fs,number_of_train)\n",
    "\n",
    "# train857 = np.array(filtered_857[len(filtered_857)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train10 = np.array(filtered_10[len(filtered_10)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train12 = np.array(filtered_12[len(filtered_12)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "# train15 = np.array(filtered_15[len(filtered_15)-256*number_of_train:]).reshape(1,256,number_of_train)\n",
    "\n",
    "train = np.array([train857, train10, train12, train15])\n",
    "\n",
    "test857 = filtered_857[fs*number_of_train:]\n",
    "test10= filtered_10[fs*number_of_train:]\n",
    "test12 = filtered_12[fs*number_of_train:]\n",
    "test15 = filtered_15[fs*number_of_train:]\n",
    "\n",
    "# test857 = filtered_857[:len(filtered_857)-256*number_of_train]\n",
    "# test10 = filtered_10[:len(filtered_10)-256*number_of_train]\n",
    "# test12 = filtered_12[:len(filtered_12)-256*number_of_train]\n",
    "# test15 = filtered_15[:len(filtered_15)-256*number_of_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "\n",
    "gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "\n",
    "mset_cca = MsetCCA_SSVEP(freqs)\n",
    "\n",
    "gcca.fit(train)\n",
    "mset_cca.fit(train)\n",
    "\n",
    "gcca_857 = []\n",
    "mset_857 =[]\n",
    "\n",
    "for begin in range(0, int(len(test857)/fs)):\n",
    "    gcca_decode = gcca.classify(test857[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_857.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test857[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_857.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 8.57hz accuracy: \", gcca_857.count(7)/len(gcca_857), '\\nMset 8.57hz accuracy: ', mset_857.count(7)/len(mset_857))\n",
    "\n",
    "gcca_10 = []\n",
    "mset_10 =[]\n",
    "\n",
    "for begin in range(0, int(len(test10)/fs)):\n",
    "    gcca_decode = gcca.classify(test10[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_10.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test10[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_10.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 10hz accuracy: \",gcca_10.count(10)/len(gcca_10), '\\nMset 10hz accuracy: ', mset_10.count(10)/len(mset_10))\n",
    "\n",
    "gcca_12 = []\n",
    "mset_12 =[]\n",
    "\n",
    "for begin in range(0, int(len(test12)/fs)):\n",
    "    gcca_decode = gcca.classify(test12[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_12.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test12[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_12.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 12hz accuracy: \",gcca_12.count(12)/len(gcca_12), '\\nMset 12hz accuracy: ', mset_12.count(12)/len(mset_12))\n",
    "\n",
    "gcca_15 = []\n",
    "mset_15 = []\n",
    "\n",
    "for begin in range(0, int(len(test15)/fs)):\n",
    "    gcca_decode = gcca.classify(test15[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    gcca_15.append(max(gcca_decode, key=gcca_decode.get))\n",
    "    mset_decode = mset_cca.classify(test15[fs*begin:fs*begin+fs].reshape(1,fs))\n",
    "    mset_15.append(max(mset_decode, key=mset_decode.get))\n",
    "\n",
    "print(\"GCCA 15hz accuracy: \",gcca_15.count(15)/len(gcca_15), '\\nMset 15hz accuracy: ', mset_15.count(15)/len(mset_15))\n",
    "\n",
    "print(mset_15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with synthetic signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def synth_x(f, Ns, noise_power=0.5, fs=256):\n",
    "    \"\"\"\n",
    "    generate a synthetic signal vector\n",
    "    \n",
    "    args:\n",
    "    Ns [int]: number of samples (time samples)\n",
    "    noise_power [float]: variance of WGN noise distribution\n",
    "    \"\"\"\n",
    "    t = np.arange(0, Ns/fs, 1/fs)\n",
    "    return np.sin(t*2*np.pi*f)*(1+random.random()*noise_power)\n",
    "\n",
    "def synth_X(f, Nc, Ns, Nt=1, noise_power=0.5, fs=256, f_std=0.02):\n",
    "    \"\"\"\n",
    "    Generate a matrix of several variations of the same target signal. This is used\n",
    "    to simulate the measurement of a common signal over multiple EEG channels \n",
    "    that have different SNR characteristics.\n",
    "    \n",
    "    args:\n",
    "    f [float]: target frequency of synthetic signal (Hz)\n",
    "    Nc [int]: number of channels\n",
    "    Ns [int]: number of samples (time samples)\n",
    "    Ns [int]: number of iid trials\n",
    "    noise_power [float]: variance of WGN noise distribution\n",
    "    fs [float]: sampling frequency (Hz)\n",
    "    f_std [float]: standard dev. of freq. in generated signal across channels to simulate interference from other frequency components over different channels\n",
    "    \"\"\"\n",
    "    def _synth():\n",
    "        X = []\n",
    "        for i in range(Nc): # simulate noisy sinusoids with varying SNR across Nc channels\n",
    "            f_i = f*(1+random.random()*f_std)\n",
    "            x = synth_x(f_i, Ns, noise_power=noise_power, fs=fs)\n",
    "\n",
    "            X.append(x)\n",
    "\n",
    "        return np.array(X)\n",
    "    \n",
    "    if Nt <= 1:\n",
    "        return _synth()\n",
    "    else:\n",
    "        trials = []\n",
    "        for i in range(Nt):\n",
    "            trials.append(_synth().flatten())\n",
    "\n",
    "        return np.array(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [7, 10, 12]\n",
    "fs=256\n",
    "\n",
    "print(synth_X(7,1,256,4).shape)\n",
    "synth_7 = (synth_X(7,1,256,4).T).reshape(1,fs,4)\n",
    "print(synth_7.shape)\n",
    "synth_10 = (synth_X(10,1,256,4).T).reshape(1,fs,4)\n",
    "synth_12 = (synth_X(12,1,256,4).T).reshape(1,fs,4)\n",
    "\n",
    "train = np.array([synth_7, synth_10, synth_12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "\n",
    "gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "\n",
    "mset_cca = MsetCCA_SSVEP(freqs)\n",
    "\n",
    "gcca.fit(train)\n",
    "mset_cca.fit(train)\n",
    "\n",
    "synth_7_test = synth_x(7,256).reshape(1,fs)\n",
    "synth_10_test = synth_x(10,256).reshape(1,fs)\n",
    "synth_12_test = synth_x(12,256).reshape(1,fs)\n",
    "\n",
    "print(\"7\")\n",
    "print(gcca.classify(synth_7_test))\n",
    "print(mset_cca.classify(synth_7_test))\n",
    "\n",
    "print(\"10\")\n",
    "print(gcca.classify(synth_10_test))\n",
    "print(mset_cca.classify(synth_10_test))\n",
    "\n",
    "print(\"12\")\n",
    "print(gcca.classify(synth_12_test))\n",
    "print(mset_cca.classify(synth_12_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change to testing on every batch and refactored into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import LeavePOut\n",
    "import random\n",
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "from eeg_lib.utils import standardise\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def synth_x(f, Ns, noise_power=0.5, fs=256):\n",
    "    t = np.arange(0, Ns/fs, 1/fs)\n",
    "    return np.sin(t*2*np.pi*f)*(1+random.random()*noise_power)\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [   [5.18442631e-04, 5.91022291e-04, 5.18442631e-04, 1.00000000e00, -1.58700686e00, 6.47826110e-01,],\n",
    "        [1.00000000e00, -6.71721317e-01, 1.00000000e00, 1.00000000e00, -1.56164716e00, 7.42956116e-01,],\n",
    "        [1.00000000e00, -1.19862825e00, 1.00000000e00, 1.00000000e00, -1.53434369e00, 8.53024717e-01,],\n",
    "        [1.00000000e00, -1.36462221e00, 1.00000000e00, 1.00000000e00, -1.52074686e00, 9.31086238e-01,],\n",
    "        [1.00000000e00, -1.41821305e00, 1.00000000e00, 1.00000000e00, -1.52570664e00, 9.80264626e-01,],\n",
    "    ])\n",
    "\n",
    "def load_array_data(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(', ')\n",
    "    for i, v in enumerate(data_file):\n",
    "        if '[' in v:\n",
    "            data_file[i] = v.replace('[','')\n",
    "        if ']\\n' in v:\n",
    "            data_file[i] = v.replace(']\\n','')\n",
    "            \n",
    "    values = [int(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def load_array_data_float(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(', ')\n",
    "    for i, v in enumerate(data_file):\n",
    "        if '[' in v:\n",
    "            data_file[i] = v.replace('[','')\n",
    "        if ']\\n' in v:\n",
    "            data_file[i] = v.replace(']\\n','')\n",
    "            \n",
    "    values = [float(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def load_array_data_online(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(',')            \n",
    "    values = [float(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def average_every_n(values, size):\n",
    "    return np.array([sum(group) / size for group in zip(*[iter(values)]*size)])\n",
    "\n",
    "def sos_filter_256(values):\n",
    "    return signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values)\n",
    "\n",
    "def process_data(data, no_samples, no_train, remove_DC=True, apply_filter=False, ds_rate=1, downsample=False):\n",
    "\n",
    "    data = data[:int(len(data)/no_samples)*no_samples]\n",
    "    \n",
    "    if remove_DC:\n",
    "        data = data - sum(data)/len(data)\n",
    "        if apply_filter:\n",
    "            data = sos_filter_256(data)[no_samples:]\n",
    "            plt.plot(data[:256])\n",
    "            \n",
    "    if downsample:\n",
    "        print(\"downsampling\",len(data))\n",
    "        data = average_every_n(data, ds_rate)\n",
    "        print(\"to\",len(data))\n",
    "        data = data[:int(len(data)/no_samples)*no_samples]\n",
    "        \n",
    "    data_reshape = data.reshape(int(len(data)/no_samples),no_samples)\n",
    "    data = data_reshape.T.reshape(1,no_samples,int(len(data)/no_samples))\n",
    "    return np.array(data)\n",
    "\n",
    "def prepare_data(data, frequency, fs, fs_synth, no_samples, no_train, remove_DC=True, apply_filter=True, downsample=False, ds_avg=1, synth_power=0, noise_power=0):\n",
    "    data = data + synth_power*synth_x(frequency, len(data), noise_power=0, fs=fs_synth)\n",
    "    values = process_data(data,no_samples,no_train,remove_DC=remove_DC,apply_filter=apply_filter,ds_rate=ds_avg,downsample=downsample)\n",
    "    return values\n",
    "\n",
    "def generate_train_test_idxs(data,no_train):\n",
    "    lpo = LeavePOut(p=no_train)\n",
    "    no_trials = data.shape[-1]\n",
    "    return list(lpo.split(range(no_trials)))\n",
    "\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def test_gcca_mset(data, data_idxs, freqs, fs, no_samples, number_runs=10):\n",
    "    # Nf x Nc x Ns x Nt\n",
    "    gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "    mset_cca = MsetCCA_SSVEP(freqs)\n",
    "    gcca_total_acc = []\n",
    "    mset_total_acc = []\n",
    "    gcca_freq_acc = dict((key,[]) for key in freqs)\n",
    "    mset_freq_acc = dict((key,[]) for key in freqs)\n",
    "\n",
    "    for i in range(number_runs):\n",
    "        # Nf x Nc x Ns x Nt\n",
    "        train = data[:,:,:,data_idxs[i][1]]\n",
    "        test = data[:,:,:,data_idxs[i][0]]\n",
    "\n",
    "        gcca.fit(train)\n",
    "        mset_cca.fit(train)\n",
    "        \n",
    "        for freq, value in enumerate(freqs):\n",
    "            gcca_res = []\n",
    "            mset_res = []\n",
    "            #print(\"############################# Frequency:\", value, \" #############################\")\n",
    "            for test_idx in range(test.shape[-1]):\n",
    "                test_now = test[freq, :, :, test_idx]\n",
    "                \n",
    "                gcca_decode = gcca.classify(test_now)\n",
    "\n",
    "                for key, prob in gcca_decode.items():\n",
    "                    gcca_decode[key] = abs(prob)\n",
    "                \n",
    "                gcca_res.append(max(gcca_decode, key=gcca_decode.get))\n",
    "                \n",
    "                mset_decode = mset_cca.classify(test_now)\n",
    "                mset_res.append(max(mset_decode, key=mset_decode.get))\n",
    "            #print(\"GCCA accuracy {gcca_acc}\\nMsetCCA {mset_acc}\".format(gcca_acc=gcca_res.count(value)/len(gcca_res),mset_acc=mset_res.count(value)/len(mset_res)))\n",
    "            \n",
    "            gcca_total_acc.append(gcca_res.count(value)/len(gcca_res))\n",
    "            mset_total_acc.append(mset_res.count(value)/len(mset_res))\n",
    "            gcca_freq_acc[value].append(gcca_res)\n",
    "            mset_freq_acc[value].append(mset_res)\n",
    "    \n",
    "    total_gcca = sum(gcca_total_acc)/len(gcca_total_acc)\n",
    "    print(\"GCCA Total Average Accuracy:\", sum(gcca_total_acc)/len(gcca_total_acc))\n",
    "    total_mset = sum(mset_total_acc)/len(mset_total_acc)\n",
    "    print(\"MsetCCA Total Average Accuracy:\", sum(mset_total_acc)/len(mset_total_acc))\n",
    "    \n",
    "    gcca_freq_scores = []\n",
    "    mset_freq_scores = []\n",
    "    \n",
    "    for key, value in gcca_freq_acc.items():\n",
    "        flattened = flatten(value)\n",
    "        print(\"GCCA {frequency}hz accuracy:{result}\".format(frequency=key, result=flattened.count(key)/len(flattened)))\n",
    "        gcca_freq_scores.append(flattened.count(key)/len(flattened))\n",
    "    for key, value in mset_freq_acc.items():\n",
    "        flattened = flatten(value)\n",
    "        print(\"MsetCCA {frequency}hz accuracy:{result}\".format(frequency=key, result=flattened.count(key)/len(flattened)))\n",
    "        mset_freq_scores.append(flattened.count(key)/len(flattened))\n",
    "        \n",
    "    return total_gcca, total_mset, gcca_freq_scores, mset_freq_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 4 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [7,10,12]\n",
    "fs_synth = 256\n",
    "fs = int(fs_synth/ds)\n",
    "over_n_seconds = 4\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 4\n",
    "removeDC = True\n",
    "applyFilter = True\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "data_file_7 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\Proper_Gain_255\\7hz_2.txt\")\n",
    "print(min(data_file_7),max(data_file_7))\n",
    "values_7 = prepare_data(data_file_7, 7, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "plt.plot(np.array(data_file_7[:256]) - np.mean(np.array(data_file_7[:256])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "\n",
    "fs=256\n",
    "# Number of samplepoints\n",
    "N = len(data_file_7)\n",
    "# sample spacing\n",
    "T = 1.0 / fs\n",
    "x = np.linspace(0.0, N*T, N)\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "yf = scipy.fftpack.fft(data_file_7)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xf[4:], 2.0/N * np.abs(yf[4:N//2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.fftpack\n",
    "\n",
    "fs=256\n",
    "# Number of samplepoints\n",
    "N = len(data_file_7)\n",
    "# sample spacing\n",
    "T = 1.0 / fs\n",
    "x = np.linspace(0.0, N*T, N)\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "yf = scipy.fftpack.fft(data_file_7)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xf[4:], 2.0/N * np.abs(yf[4:N//2]))\n",
    "plt.show()\n",
    "\n",
    "filtered = sos_filter_256(data_file_7)\n",
    "\n",
    "fs=64\n",
    "# Number of samplepoints\n",
    "N = len(filtered)\n",
    "# sample spacing\n",
    "T = 1.0 / fs\n",
    "x = np.linspace(0.0, N*T, N)\n",
    "xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "yf = scipy.fftpack.fft(filtered)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(xf[4:], 2.0/N * np.abs(yf[4:N//2]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 4 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [7,10,12]\n",
    "fs_synth = 256\n",
    "fs = int(fs_synth/ds)\n",
    "over_n_seconds = 4\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 4\n",
    "removeDC = True\n",
    "applyFilter = True\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "# data_file_7 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\Proper_Gain_255\\7hz_2.txt\")\n",
    "data_file_7 = load_array_data(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/Proper_Gain_255/7hz_2.txt\")\n",
    "print(min(data_file_7),max(data_file_7))\n",
    "values_7 = prepare_data(data_file_7, 7, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "# data_file_10 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\Proper_Gain_255\\10hz_2.txt\")\n",
    "data_file_7 = load_array_data(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/Proper_Gain_255/10hz_2.txt\")\n",
    "print(min(data_file_10),max(data_file_10))\n",
    "values_10 = prepare_data(data_file_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "# data_file_12 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\Proper_Gain_255\\12hz_2.txt\")\n",
    "data_file_7 = load_array_data(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/Proper_Gain_255/12hz_2.txt\")\n",
    "print(min(data_file_12),max(data_file_12))\n",
    "values_12 = prepare_data(data_file_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "print(values_12.shape, values_10.shape, values_7.shape)\n",
    "\n",
    "data_packed = np.array([values_7, values_10, values_12])\n",
    "\n",
    "print(data_packed.shape)\n",
    "\n",
    "train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "print(len(train_test_idxs))\n",
    "print((train_test_idxs[0]))\n",
    "test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 256, 26) (1, 256, 26) (1, 256, 26)\n",
      "(3, 1, 256, 26)\n",
      "14950\n",
      "(array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
      "       21, 22, 23, 24, 25]), array([0, 1, 2, 3]))\n",
      "GCCA Total Average Accuracy: 0.3636363636363636\n",
      "MsetCCA Total Average Accuracy: 0.34848484848484845\n",
      "GCCA 7hz accuracy:0.5909090909090909\n",
      "GCCA 10hz accuracy:0.45454545454545453\n",
      "GCCA 12hz accuracy:0.045454545454545456\n",
      "MsetCCA 7hz accuracy:1.0\n",
      "MsetCCA 10hz accuracy:0.0\n",
      "MsetCCA 12hz accuracy:0.045454545454545456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3636363636363636,\n",
       " 0.34848484848484845,\n",
       " [0.5909090909090909, 0.45454545454545453, 0.045454545454545456],\n",
       " [1.0, 0.0, 0.045454545454545456])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = 1 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [7,10,12]\n",
    "fs_synth = 256\n",
    "fs = int(fs_synth/ds)\n",
    "over_n_seconds = 1\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 4\n",
    "removeDC = True\n",
    "applyFilter = False\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "data_file_7 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\decreased_noise_location\\7_1.txt\")\n",
    "# data_file_7 = data_file_7[:1024] + data_file_7[2048:]#data_file_7[3072:]\n",
    "data_file_7 = data_file_7[1024:]\n",
    "values_7 = prepare_data(data_file_7, 7, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "data_file_10 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\decreased_noise_location\\10_1.txt\")\n",
    "# data_file_10 = data_file_10[:1024] + data_file_10[2048:]#data_file_10[3072:].\n",
    "data_file_10 = data_file_10[1024:]\n",
    "values_10 = prepare_data(data_file_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "data_file_12 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\decreased_noise_location\\12_1.txt\")\n",
    "# data_file_12 = data_file_12[:1024] + data_file_12[2048:]#data_file_12[3072:]\n",
    "data_file_12 = data_file_12[1024:]\n",
    "values_12 = prepare_data(data_file_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "print(values_12.shape, values_10.shape, values_7.shape)\n",
    "\n",
    "data_packed = np.array([values_7, values_10, values_12])\n",
    "\n",
    "print(data_packed.shape)\n",
    "\n",
    "train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "print(len(train_test_idxs))\n",
    "print((train_test_idxs[0]))\n",
    "test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 1 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [8.57,10,12,15]\n",
    "fs_synth = 256\n",
    "fs = fs_synth/ds\n",
    "number_of_samples = 256\n",
    "number_of_train = 4\n",
    "removeDC = False\n",
    "applyFilter = False\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\online_dataset\\data\\subject11.csv\",sep=';')\n",
    "s1_8_57 = standardise(df['F1'].to_numpy())\n",
    "s1_8_57 = prepare_data(s1_8_57, 8.57, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "s1_10 = standardise(df['F2'].to_numpy())\n",
    "s1_10 = prepare_data(s1_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "s1_12 = standardise(df['F3'].to_numpy())\n",
    "s1_12 = prepare_data(s1_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "s1_15 = standardise(df['F4'].to_numpy())\n",
    "s1_15 = prepare_data(s1_15, 15, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "print(s1_15.shape, s1_12.shape, s1_10.shape, s1_8_57.shape)\n",
    "\n",
    "data_packed = np.array([s1_8_57, s1_10, s1_12, s1_15])\n",
    "\n",
    "print(data_packed.shape)\n",
    "\n",
    "train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "print(len(train_test_idxs))\n",
    "test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 1 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [7,10,12]\n",
    "fs_synth = 64\n",
    "fs = 64\n",
    "over_n_seconds = 1\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 4\n",
    "removeDC = False\n",
    "applyFilter = False\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "data_file_all = load_array_data_float(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/livedata/on_board_downsample_filter1/decoding_data.txt\")\n",
    "test_7 = data_file_all[:256*10]\n",
    "test_10 = data_file_all[256*10:256*20]\n",
    "test_12 = data_file_all[256*20:256*30]\n",
    "\n",
    "print(len(test_7),len(test_10),len(test_12))\n",
    "\n",
    "train_7 = load_array_data_float(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/livedata/on_board_downsample_filter1/7hz_calibration.txt\")\n",
    "train_10 = load_array_data_float(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/livedata/on_board_downsample_filter1/10hz_calibration.txt\")\n",
    "train_12 = load_array_data_float(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/livedata/on_board_downsample_filter1/12hz_calibration.txt\")\n",
    "# train_12 = load_array_data_float(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\livedata\\on_board_downsample_filter1\\12hz_calibration.txt\")\n",
    "\n",
    "print(len(train_7),len(train_10),len(train_12))\n",
    "\n",
    "data_file_7 = flatten([train_7, test_7])\n",
    "data_file_10 = flatten([train_10, test_10])\n",
    "data_file_12 = flatten([train_12, test_12])\n",
    "\n",
    "values_7 = prepare_data(data_file_7, 7, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "values_10 = prepare_data(data_file_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "values_12 = prepare_data(data_file_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "print(values_12.shape, values_10.shape, values_7.shape)\n",
    "\n",
    "data_packed = np.array([values_7, values_10, values_12])\n",
    "\n",
    "print(data_packed.shape)\n",
    "\n",
    "train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "print(len(train_test_idxs))\n",
    "print((train_test_idxs[0]))\n",
    "test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ds = 1 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [8,9,10]\n",
    "fs_synth = 250\n",
    "fs = int(fs_synth/ds)\n",
    "over_n_seconds = 1\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 4\n",
    "removeDC = False\n",
    "applyFilter = False\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "gcca_arr = {}\n",
    "mset_arr = {}\n",
    "gcca_f = {'Pz':[], 'PO5':[], 'PO3':[], 'POz':[], 'PO4':[], 'PO6':[], 'O1':[], 'Oz':[], 'O2':[]}\n",
    "mset_f = {'Pz':[], 'PO5':[], 'PO3':[], 'POz':[], 'PO4':[], 'PO6':[], 'O1':[], 'Oz':[], 'O2':[]}\n",
    "\n",
    "blocks = [i for i in range(1,7)]\n",
    "channel_locations = ['Pz', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2']\n",
    "# random.shuffle(blocks)\n",
    "print(blocks)\n",
    "for channel in range(1,10):\n",
    "    data_file_7 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        # data_file_7 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/8hz/8hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "        data_file_7 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\8hz\\8hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "\n",
    "    values_7 = prepare_data(data_file_7, 8, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    data_file_10 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        # data_file_10 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/10hz/10hz_channel_0{c}_0{b}\".format(c=channel,b=block))\n",
    "        data_file_10 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\9hz\\9hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "\n",
    "    values_10 = prepare_data(data_file_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    data_file_12 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        # data_file_12 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/12hz/12hz_channel_0{c}_0{b}\".format(c=channel,b=block))\n",
    "        data_file_12 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\10hz\\10hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "    values_12 = prepare_data(data_file_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    print(values_12.shape, values_10.shape, values_7.shape)\n",
    "\n",
    "    data_packed = np.array([values_7, values_10, values_12])\n",
    "\n",
    "    print(data_packed.shape)\n",
    "\n",
    "    train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "    print(len(train_test_idxs))\n",
    "    print((train_test_idxs[0]))\n",
    "    gcca, mset, gccaf, msetf = test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)\n",
    "#     gcca_arr.append(gcca)\n",
    "    gcca_arr[channel_locations[channel-1]] = gcca\n",
    "#     mset_arr.append(mset)\n",
    "    mset_arr[channel_locations[channel-1]] = mset\n",
    "#     gcca_f.append(gccaf)\n",
    "    gcca_f[channel_locations[channel-1]].append(gccaf)\n",
    "#     mset_f.append(msetf)\n",
    "    mset_f[channel_locations[channel-1]].append(msetf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# print(sum(gcca_arr)/len(gcca_arr))\n",
    "# print(\"GCCA:\", gcca_arr)\n",
    "print(\"GCCA:\", json.dumps(gcca_arr, indent=4, sort_keys=True))\n",
    "# print(sum(mset_arr)/len(mset_arr))\n",
    "# print(\"MsetCCA:\", mset_arr)\n",
    "print(\"MsetCCA:\", json.dumps(mset_arr, indent=4, sort_keys=True))\n",
    "\n",
    "print(\"GCCA Frequencies:\", gcca_f)\n",
    "print(\"MsetCCA Frequencies:\", mset_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# print(sum(gcca_arr)/len(gcca_arr))\n",
    "# print(\"GCCA:\", gcca_arr)\n",
    "print(\"GCCA:\", json.dumps(gcca_arr, indent=4, sort_keys=True))\n",
    "# print(sum(mset_arr)/len(mset_arr))\n",
    "# print(\"MsetCCA:\", mset_arr)\n",
    "print(\"MsetCCA:\", json.dumps(mset_arr, indent=4, sort_keys=True))\n",
    "\n",
    "print(\"GCCA Frequencies:\", gcca_f)\n",
    "print(\"MsetCCA Frequencies:\", mset_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 512\n",
    "filt_ord = 10\n",
    "pb_rip = 0.2\n",
    "sb_atten = 80\n",
    "\n",
    "fc_lo = 4 # pass band lower freq\n",
    "fc_hi = 50 # pass band upp freq \n",
    "wc_lo = fc_lo/(fs*0.5)\n",
    "wc_hi = fc_hi/(fs*0.5)\n",
    "\n",
    "sos_ellip = signal.ellip(filt_ord, pb_rip, sb_atten, (wc_lo, wc_hi), btype='bandpass', output='sos')\n",
    "\n",
    "filtered = signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, data_file_7[:512])\n",
    "# filtered = signal.sosfilt(sos_ellip, data_file_7[:256])\n",
    "\n",
    "plt.plot(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_7_plot = data_file_7 - sum(data_file_7)/len(data_file_7)\n",
    "plt.plot(data_file_7_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, sosfilt, sosfreqz\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog=False, btype='band', output='sos')\n",
    "        return sos\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "        sos = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "        y = sosfilt(sos, data)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_butter = butter_bandpass_filter(data_file_7_plot, 4, 28, 256, order=10)\n",
    "plt.plot(filter_butter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\fs512hz_gain255_30s\\7hz\\7hz_LED2.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [1171, 1271, 1424, 1235, 999, 960, 1205, 1424, 1319, 1071, 999, 1219, 1466, 1392, 1148, 993, 1181, 1411, 1393, 1159, 999, 1174, 1409, 1435, 1205, 1013, 1165, 1424, 1488, 1266, 1052, 1149, 1412, 1522, 1323, 1078, 1107, 1573, 1595, 1405, 1203, 1184, 1367, 1552, 1424, 1200, 1119, 1344, 1533, 1453, 1242, 1135, 1419, 1533, 1462, 1201, 1062, 1253, 1447, 1419, 1166, 1005, 1200, 1468, 1520, 1281, 1085, 1261, 1445, 1535, 1296, 1072, 1131, 1381, 1503, 1312, 1091, 1109, 1353, 1509, 1343, 1089, 1067, 1301, 1479, 1354, 1109, 1022, 1233, 1454, 1366, 1125, 976, 1289, 1411, 1399, 1191, 1043, 1213, 1459, 1476, 1254, 1066, 1213, 1461, 1510, 1261, 1039, 1108, 1368, 1491, 1311, 1094, 1126, 1338, 1498, 1269, 1123, 1118, 1328, 1473, 1326, 1089, 1058, 1296, 1478, 1373, 1136, 1043, 1287, 1543, 1479, 1200, 1061, 1234, 1462, 1466, 1200, 998, 1130, 1360, 1398, 1185, 976, 1104, 1335, 1418, 1207, 978, 1071, 1296, 1439, 1249, 1013, 1045, 1281, 1426, 1278, 1047, 1018, 1263, 1437, 1337, 1136, 1065, 1302, 1490, 1419, 1187, 1086, 1289, 1509, 1410, 1189, 1009, 1184, 1401, 1397, 1166, 999, 1155, 1406, 1456, 1248, 1046, 1159, 1394, 1462, 1248, 1035, 1138, 1403, 1533, 1319, 1085, 1074, 1281, 1433, 1152, 1040, 974, 1213, 1406, 1313, 1063, 993, 1243, 1507, 1443, 1165, 1008, 1200, 1472, 1465, 1198, 993, 1130, 1388, 1469, 1264, 1065, 1146, 1356, 1472, 1255, 1090, 1171, 1390, 1475, 1264, 1031, 1102, 1349, 1511, 1328, 1092, 1116, 1378, 1557, 1406, 1138, 1047, 1519, 1618, 1534, 1318, 1243, 1259, 1328, 1365, 1377, 1396, 1408, 1419, 1456, 1520, 1184, 1395, 1445, 1431, 1226, 1117, 1290, 1463, 1380, 1155, 1049, 1271, 1501, 1466, 1232, 1047, 1372, 1479, 1450, 1215, 1002, 1168, 1419, 1485, 1260, 1023, 1104, 1330, 1425, 1221, 1021, 1099, 1335, 1502, 1353, 1149, 1136, 1344, 1502, 1337, 1103, 1082, 1279, 1461, 1338, 1087, 1005, 1232, 1456, 1409, 1181, 1050, 1255, 1488, 1471, 1222, 1065, 1227, 1487, 1520, 1309, 1104, 1216, 1433, 1527, 1315, 1111, 1157, 1387, 1481, 1291, 1063, 1089, 1347, 1525, 1377, 1169, 1158, 1397, 1585, 1459, 1232, 1168, 1367, 1578, 1488, 1261, 1125, 1291, 1482, 1429, 1221, 1098, 1285, 1518, 1487, 1253, 1015, 1161, 1413, 1491, 1287, 1047, 1118, 1370, 1482, 1303, 1118, 1198, 1467, 1613, 1391, 1104, 1103, 1365, 1582, 1438, 1215, 1136, 1345, 1547, 1358, 1186, 1102, 1323, 1533, 1462, 1199, 1039, 1223, 1445, 1445, 1226, 1069, 1220, 1445, 1473, 1234, 1009, 1113, 1344, 1424, 1233, 1045, 1143, 1401, 1551, 1221, 1119, 1124, 1322, 1477, 1334, 1169, 1198, 1424, 1579, 1446, 1168, 1104, 1361, 1564, 1475, 1217, 1103, 1309, 1531, 1473, 1227, 1057, 1239, 1474, 1474, 1247, 1046, 1189, 1411, 1474, 1279, 1104, 1223, 1427, 1517, 1295, 1078, 1152, 1417, 1532, 1354, 1138, 1138, 1349, 1493, 1328, 1110, 1102, 1324, 1513, 1392, 1161, 1097, 1315, 1530, 1435, 1162, 1280, 1314, 1573, 1609, 1360, 1136, 1281, 1531, 1568, 1329, 1125, 1242, 1456, 1496, 1279, 1090, 1201, 1455, 1570, 1349, 1131, 1200, 1434, 1595, 1414, 1187, 1166, 1394, 1559, 1395, 1157, 1086, 1345, 1600, 1491, 1263, 1137, 1344, 1562, 1532, 1595, 1600, 1618, 1615, 1613, 1601, 1593, 1584, 1499, 1485, 1222, 1189, 1435, 1591, 1408, 1182, 1168, 1399, 1599, 1484, 1267, 1193, 1418, 1616, 1441, 1289, 1167, 1358, 1559, 1475, 1259, 1121, 1332, 1610, 1614, 1382, 1189, 1323, 1551, 1588, 1346, 1142, 1269, 1501, 1587, 1360, 1117, 1183, 1423, 1589, 1289, 1159, 1191, 1465, 1644, 1498, 1229, 1187, 1407, 1638, 1533, 1273, 1174, 1391, 1593, 1550, 1312, 1168, 1370, 1593, 1575, 1341, 1184, 1373, 1633, 1648, 1392, 1154, 1275, 1505, 1584, 1397, 1227, 1299, 1559, 1625, 1398, 1168, 1220, 1498, 1634, 1472, 1228, 1218, 1461, 1643, 1470, 1232, 1174, 1424, 1641, 1510, 1253, 1116, 1313, 1535, 1514, 1297, 1157, 1339, 1570, 1533, 1307, 1137, 1280, 1549, 1564, 1357, 1136, 1257, 1493, 1591, 1380, 1152, 1202, 1438, 1552, 1393, 1147, 1216, 1407, 1549, 1372, 1143, 1141, 1390, 1555, 1403, 1168, 1116, 1360, 1595, 1488, 1233, 1117, 1361, 1611, 1580, 1308, 1134, 1311, 1566, 1584, 1339, 1133, 1349, 1503, 1587, 1380, 1180, 1289, 1511, 1614, 1424, 1183, 1250, 1472, 1607, 1447, 1212, 1187, 1424, 1600, 1455, 1207, 1161, 1382, 1583, 1479, 1221, 1121, 1432, 1511, 1434, 1183, 1055, 1321, 1584, 1595, 1334, 1105, 1264, 1520, 1594, 1391, 1173, 1264, 1483, 1589, 1392, 1177, 1232, 1470, 1607, 1417, 1174, 1201, 1437, 1595, 1430, 1183, 1152, 1381, 1610, 1500, 1282, 1203, 1401, 1628, 1561, 1307, 1203, 1386, 1593, 1546, 1314, 1136, 1335, 1562, 1534, 1328, 1153, 1315, 1570, 1573, 1372, 1191, 1305, 1558, 1648, 1413, 1179, 1207, 1429, 1552, 1358, 1129, 1159, 1437, 1618, 1469, 1216, 1155, 1394, 1607, 1515, 1402, 1416, 1504, 1552, 1557, 1583, 1595, 1603, 1621, 1636, 1490, 1354, 1152, 1260, 1483, 1594, 1381, 1161, 1210, 1468, 1616, 1422, 1146, 1149, 1356, 1527, 1408, 1181, 1150, 1387, 1600, 1501, 1241, 1136, 1328, 1558, 1522, 1299, 1152, 1324, 1520, 1518, 1299, 1151, 1298, 1524, 1553, 1351, 1156, 1345, 1515, 1616, 1381, 1175, 1232, 1461, 1585, 1381, 1142, 1163, 1392, 1570, 1423, 1206, 1199, 1462, 1649, 1526, 1271, 1168, 1367, 1580, 1505, 1294, 1155, 1441, 1535, 1494, 1275, 1134, 1338, 1553, 1552, 1317, 1134, 1303, 1569, 1640, 1402, 1230, 1328, 1562, 1643, 1391, 1147, 1225, 1469, 1630, 1430, 1181, 1177, 1411, 1605, 1456, 1217, 1169, 1402, 1616, 1506, 1265, 1169, 1407, 1631, 1581, 1326, 1194, 1374, 1573, 1510, 1270, 1123, 1341, 1600, 1617, 1343, 1129, 1257, 1522, 1616, 1419, 1193, 1242, 1489, 1600, 1392, 1168, 1199, 1451, 1631, 1488, 1258, 1258, 1483, 1653, 1509, 1270, 1191, 1403, 1584, 1507, 1280, 1189, 1402, 1616, 1525, 1317, 1152, 1341, 1570, 1550, 1292, 1115, 1288, 1549, 1634, 1422, 1195, 1313, 1535, 1630, 1443, 1227, 1289, 1513, 1628, 1438, 1187, 1183, 1394, 1571, 1325, 1171, 1157, 1399, 1612, 1514, 1289, 1223, 1442, 1626, 1510, 1273, 1204, 1392, 1620, 1581, 1318, 1136, 1302, 1552, 1583, 1360, 1169, 1306, 1529, 1616, 1270, 1187, 1311, 1550, 1668, 1456, 1195, 1258, 1495, 1682, 1517, 1283, 1269, 1502, 1659, 1490, 1259, 1207, 1442, 1649, 1571, 1339, 1232, 1474, 1689, 1630, 1366, 1189, 1360, 1588, 1600, 1378, 1223, 1420, 1683, 1717, 1456, 1221, 1309, 1583, 1667, 1514, 1293, 1332, 1520, 1631, 1443, 1226, 1280, 1543, 1735, 1168, 1165, 1161, 1175, 1183, 1200, 1211, 1217, 1255, 1489, 1368, 1583, 1595, 1361, 1168, 1328, 1562, 1631, 1406, 1165, 1264, 1513, 1618, 1424, 1188, 1226, 1476, 1629, 1451, 1227, 1250, 1511, 1694, 1553, 1296, 1250, 1483, 1659, 1517, 1271, 1195, 1439, 1666, 1603, 1330, 1173, 1359, 1597, 1567, 1378, 1211, 1389, 1617, 1648, 1429, 1258, 1397, 1634, 1705, 1451, 1233, 1321, 1552, 1665, 1467, 1232, 1265, 1500, 1654, 1462, 1232, 1218, 1473, 1686, 1495, 1296, 1225, 1444, 1686, 1585, 1332, 1206, 1423, 1684, 1649, 1419, 1270, 1457, 1744, 1757, 1547, 1320, 1466, 1664, 1731, 1487, 1252, 1359, 1600, 1696, 1505, 1259, 1360, 1621, 1763, 1555, 1285, 1282, 1535, 1738, 1597, 1339, 1270, 1514, 1709, 1607, 1368, 1271, 1502, 1719, 1667, 1392, 1248, 1437, 1680, 1696, 1473, 1279, 1407, 1632, 1664, 1462, 1280, 1417, 1623, 1694, 1465, 1253, 1353, 1613, 1711, 1513, 1271, 1309, 1520, 1669, 1471, 1249, 1264, 1535, 1746, 1600, 1318, 1246, 1475, 1709, 1631, 1370, 1227, 1407, 1633, 1607, 1408, 1263, 1453, 1685, 1691, 1490, 1320, 1470, 1679, 1685, 1450, 1254, 1377, 1633, 1728, 1494, 1275, 1407, 1622, 1766, 1586, 1296, 1264, 1492, 1687, 1556, 1322, 1265, 1478, 1670, 1558, 1339, 1261, 1477, 1675, 1594, 1377, 1250, 1441, 1657, 1602, 1363, 1233, 1527, 1688, 1700, 1450, 1229, 1349, 1584, 1669, 1446, 1232, 1319, 1584, 1697, 1565, 1334, 1338, 1546, 1702, 1550, 1343, 1360, 1600, 1759, 1588, 1339, 1276, 1654, 1725, 1631, 1375, 1249, 1479, 1709, 1674, 1429, 1261, 1456, 1693, 1680, 1419, 1242, 1375, 1616, 1653, 1441, 1253, 1378, 1633, 1724, 1506, 1263, 1744, 1745, 1741, 1722, 1715, 1702, 1687, 1680, 1642, 1459, 1168, 1351, 1575, 1547, 1300, 1136, 1322, 1561, 1587, 1267, 1225, 1375, 1594, 1626, 1379, 1168, 1271, 1521, 1651, 1461, 1217, 1248, 1456, 1601, 1456, 1245, 1243, 1476, 1647, 1535, 1327, 1267, 1488, 1687, 1574, 1328, 1227, 1424, 1647, 1601, 1358, 1219, 1449, 1695, 1680, 1409, 1189, 1332, 1603, 1643, 1430, 1233, 1355, 1605, 1705, 1468, 1220, 1282, 1523, 1679, 1500, 1251, 1286, 1467, 1626, 1473, 1248, 1228, 1471, 1658, 1557, 1331, 1264, 1469, 1657, 1573, 1377, 1271, 1465, 1628, 1535, 1295, 1165, 1408, 1647, 1664, 1424, 1239, 1484, 1654, 1709, 1443, 1223, 1335, 1589, 1709, 1499, 1266, 1318, 1556, 1713, 1568, 1325, 1278, 1489, 1669, 1546, 1315, 1280, 1494, 1710, 1619, 1363, 1254, 1572, 1664, 1603, 1379, 1221, 1415, 1648, 1647, 1424, 1247, 1385, 1631, 1677, 1439, 1265, 1373, 1610, 1698, 1515, 1324, 1391, 1595, 1705, 1488, 1275, 1308, 1549, 1697, 1494, 1299, 1264, 1508, 1709, 1584, 1310, 1215, 1406, 1633, 1599, 1350, 1239, 1431, 1647, 1627, 1381, 1228, 1406, 1634, 1638, 1392, 1226, 1390, 1626, 1699, 1487, 1284, 1394, 1633, 1727, 1505, 1291, 1353, 1597, 1731, 1552, 1309, 1327, 1534, 1664, 1490, 1241, 1216, 1472, 1704, 1583, 1315, 1229, 1456, 1690, 1604, 1390, 1238, 1466, 1702, 1673, 1424, 1222, 1395, 1635, 1680, 1471, 1263, 1393, 1631, 1703, 1502, 1279, 1351, 1593, 1712, 1505, 1285, 1299, 1572, 1744, 1503, 1339, 1280, 1475, 1678, 1580, 1354, 1296, 1519, 1730, 1654, 1415, 1315, 1472, 1659, 1618, 1367, 1216, 1404, 1622, 1616, 1383, 1179, 1344, 1586, 1632, 1232, 1446, 1455, 1532, 1575, 1584, 1605, 1618, 1630, 1664, 1696, 1665, 1424, 1309, 1486, 1669, 1610, 1405, 1296, 1595, 1682, 1634, 1390, 1217, 1403, 1637, 1655, 1421, 1218, 1344, 1639, 1712, 1534, 1311, 1339, 1533, 1661, 1488, 1270, 1289, 1511, 1664, 1502, 1257, 1233, 1452, 1627, 1503, 1275, 1246, 1493, 1700, 1611, 1340, 1205, 1408, 1648, 1625, 1370, 1233, 1418, 1636, 1659, 1450, 1284, 1421, 1673, 1685, 1450, 1232, 1347, 1598, 1687, 1489, 1247, 1323, 1575, 1744, 1583, 1311, 1305, 1526, 1699, 1579, 1371, 1363, 1571, 1741, 1606, 1354, 1298, 1530, 1761, 1679, 1425, 1264, 1438, 1670, 1651, 1452, 1285, 1461, 1690, 1701, 1461, 1281, 1417, 1712, 1809, 1603, 1355, 1426, 1655, 1738, 1543, 1312, 1355, 1603, 1763, 1570, 1336, 1313, 1552, 1734, 1529, 1335, 1253, 1490, 1728, 1655, 1403, 1243, 1427, 1661, 1657, 1449, 1287, 1433, 1651, 1673, 1439, 1259, 1397, 1625, 1701, 1472, 1284, 1401, 1664, 1791, 1486, 1360, 1388, 1613, 1759, 1585, 1333, 1326, 1574, 1780, 1698, 1439, 1371, 1578, 1751, 1681, 1444, 1338, 1526, 1726, 1666, 1425, 1267, 1471, 1731, 1726, 1490, 1299, 1467, 1712, 1759, 1544, 1344, 1477, 1712, 1781, 1580, 1360, 1424, 1696, 1794, 1577, 1344, 1360, 1601, 1776, 1622, 1379, 1348, 1581, 1776, 1663, 1428, 1349, 1549, 1737, 1663, 1437, 1309, 1509, 1730, 1711, 1467, 1278, 1427, 1647, 1658, 1445, 1281, 1409, 1637, 1689, 1478, 1264, 1365, 1609, 1734, 1554, 1354, 1445, 1647, 1789, 1617, 1362, 1349, 1583, 1759, 1625, 1372, 1327, 1519, 1712, 1611, 1406, 1328, 1550, 1744, 1661, 1388, 1247, 1454, 1712, 1713, 1473, 1266, 1495, 1678, 1382, 1372, 1319, 1300, 1298, 1293, 1287, 1284, 1291, 1487, 1589, 1765, 1614, 1345, 1282, 1516, 1728, 1584, 1399, 1291, 1517, 1743, 1701, 1455, 1268, 1463, 1696, 1727, 1534, 1385, 1507, 1727, 1731, 1488, 1269, 1382, 1628, 1707, 1489, 1255, 1315, 1572, 1729, 1442, 1318, 1330, 1582, 1775, 1623, 1362, 1296, 1498, 1697, 1603, 1374, 1264, 1488, 1687, 1638, 1409, 1263, 1449, 1653, 1653, 1433, 1291, 1461, 1685, 1695, 1491, 1295, 1422, 1620, 1655, 1425, 1219, 1328, 1610, 1761, 1584, 1346, 1356, 1564, 1683, 1522, 1338, 1335, 1584, 1742, 1600, 1366, 1328, 1554, 1745, 1635, 1383, 1296, 1505, 1739, 1690, 1472, 1315, 1507, 1744, 1756, 1535, 1334, 1485, 1765, 1807, 1591, 1334, 1377, 1616, 1734, 1558, 1347, 1395, 1630, 1791, 1611, 1387, 1392, 1617, 1790, 1652, 1392, 1324, 1530, 1743, 1648, 1410, 1307, 1547, 1783, 1708, 1462, 1310, 1479, 1715, 1724, 1498, 1309, 1486, 1725, 1754, 1522, 1328, 1518, 1698, 1781, 1585, 1323, 1399, 1634, 1754, 1565, 1331, 1361, 1620, 1791, 1644, 1407, 1389, 1614, 1807, 1680, 1444, 1385, 1608, 1827, 1766, 1535, 1406, 1694, 1759, 1687, 1437, 1295, 1488, 1743, 1763, 1559, 1360, 1483, 1714, 1773, 1547, 1333, 1417, 1623, 1744, 1558, 1359, 1438, 1653, 1774, 1573, 1328, 1355, 1619, 1813, 1646, 1406, 1326, 1554, 1795, 1711, 1475, 1343, 1521, 1758, 1714, 1463, 1296, 1443, 1661, 1689, 1497, 1360, 1510, 1738, 1762, 1500, 1280, 1365, 1631, 1743, 1560, 1351, 1407, 1633, 1766, 1602, 1382, 1392, 1605, 1739, 1584, 1324, 1313, 1574, 1786, 1659, 1401, 1297, 1505, 1719, 1658, 1414, 1286, 1498, 1728, 1687, 1495, 1343, 1730, 1739, 1762, 1749, 1747, 1735, 1727, 1718, 1654, 1458, 1361, 1375, 1619, 1808, 1618, 1370, 1314, 1519, 1722, 1629, 1409, 1299, 1518, 1731, 1680, 1443, 1295, 1491, 1702, 1677, 1427, 1233, 1363, 1611, 1641, 1435, 1246, 1381, 1626, 1713, 1520, 1315, 1426, 1605, 1707, 1495, 1288, 1334, 1596, 1793, 1644, 1423, 1363, 1593, 1782, 1662, 1424, 1329, 1526, 1769, 1700, 1471, 1318, 1489, 1695, 1697, 1499, 1354, 1680, 1791, 1798, 1587, 1363, 1473, 1696, 1750, 1545, 1341, 1462, 1699, 1790, 1533, 1315, 1328, 1582, 1743, 1581, 1365, 1380, 1605, 1779, 1646, 1413, 1363, 1562, 1732, 1603, 1363, 1264, 1500, 1743, 1710, 1493, 1343, 1514, 1703, 1678, 1424, 1266, 1450, 1675, 1717, 1497, 1318, 1460, 1697, 1751, 1550, 1328, 1417, 1676, 1780, 1592, 1331, 1360, 1623, 1795, 1653, 1392, 1334, 1556, 1744, 1647, 1392, 1361, 1569, 1776, 1680, 1427, 1290, 1511, 1747, 1713, 1474, 1291, 1461, 1691, 1702, 1503, 1327, 1465, 1702, 1757, 1543, 1329, 1426, 1664, 1787, 1590, 1357, 1415, 1637, 1765, 1586, 1355, 1351, 1580, 1751, 1635, 1409, 1378, 1619, 1829, 1615, 1407, 1265, 1484, 1754, 1743, 1508, 1328, 1533, 1781, 1778, 1568, 1381, 1535, 1772, 1827, 1585, 1349, 1459, 1693, 1806, 1591, 1374, 1445, 1664, 1787, 1447, 1329, 1360, 1613, 1775, 1635, 1391, 1332, 1559, 1743, 1611, 1363, 1264, 1510, 1732, 1683, 1455, 1311, 1503, 1710, 1662, 1455, 1309, 1519, 1764, 1818, 1601, 1355, 1463, 1647, 1692, 1488, 1307, 1415, 1649, 1759, 1520, 1280, 1335, 1648, 1831, 1677, 1421, 1341, 1520, 1681, 1567, 1346, 1323, 1553, 1749, 1645, 1409, 1293, 1482, 1710, 1675, 1382, 1392, 1447, 1483, 1490, 1515, 1524, 1533, 1583, 1793, 1825, 1635, 1391, 1394, 1644, 1830, 1665, 1411, 1356, 1593, 1807, 1734, 1493, 1401, 1616, 1808, 1773, 1524, 1415, 1568, 1797, 1776, 1583, 1456, 1643, 1901, 1914, 1671, 1456, 1520, 1738, 1776, 1578, 1365, 1455, 1711, 1861, 1691, 1461, 1474, 1670, 1823, 1674, 1431, 1426, 1641, 1814, 1703, 1498, 1459, 1698, 1889, 1795, 1552, 1418, 1614, 1840, 1779, 1563, 1424, 1623, 1846, 1856, 1579, 1361, 1508, 1778, 1844, 1638, 1367, 1467, 1719, 1823, 1605, 1357, 1415, 1682, 1877, 1730, 1495, 1467, 1667, 1837, 1712, 1456, 1463, 1680, 1863, 1755, 1513, 1401, 1648, 1859, 1816, 1586, 1413, 1619, 1810, 1809, 1584, 1406, 1577, 1806, 1815, 1590, 1384, 1471, 1722, 1825, 1616, 1397, 1467, 1673, 1755, 1543, 1331, 1389, 1667, 1835, 1641, 1370, 1311, 1595, 1790, 1710, 1471, 1396, 1596, 1797, 1712, 1470, 1348, 1565, 1817, 1799, 1552, 1379, 1520, 1694, 1713, 1500, 1360, 1535, 1791, 1850, 1633, 1419, 1506, 1759, 1840, 1616, 1382, 1415, 1657, 1822, 1642, 1408, 1402, 1643, 1839, 1711, 1503, 1460, 1690, 1872, 1734, 1488, 1382, 1590, 1805, 1744, 1523, 1422, 1625, 1872, 1820, 1600, 1426, 1594, 1834, 1838, 1594, 1363, 1478, 1732, 1823, 1634, 1407, 1565, 1712, 1824, 1638, 1414, 1447, 1678, 1840, 1680, 1443, 1414, 1621, 1821, 1695, 1469, 1406, 1622, 1815, 1731, 1477, 1321, 1514, 1733, 1709, 1472, 1297, 1577, 1751, 1754, 1522, 1349, 1493, 1713, 1781, 1567, 1359, 1466, 1738, 1859, 1667, 1451, 1506, 1733, 1872, 1703, 1488, 1465, 1680, 1821, 1666, 1451, 1412, 1662, 1843, 1706, 1453, 1360, 1776, 1771, 1713, 1680, 1674, 1652, 1641, 1631, 1600, 1471, 1433, 1833, 1520, 1468, 1493, 1703, 1855, 1690, 1451, 1426, 1647, 1840, 1745, 1553, 1478, 1710, 1868, 1798, 1551, 1387, 1582, 1792, 1801, 1595, 1436, 1623, 1841, 1866, 1635, 1429, 1572, 1840, 1913, 1677, 1391, 1399, 1598, 1717, 1567, 1369, 1421, 1662, 1779, 1583, 1349, 1360, 1600, 1805, 1679, 1424, 1360, 1600, 1815, 1737, 1503, 1409, 1614, 1822, 1775, 1507, 1319, 1495, 1740, 1781, 1593, 1405, 1567, 1793, 1806, 1569, 1339, 1443, 1711, 1825, 1648, 1424, 1456, 1680, 1826, 1665, 1457, 1501, 1643, 1780, 1645, 1450, 1427, 1636, 1808, 1679, 1459, 1409, 1639, 1873, 1791, 1583, 1426, 1603, 1779, 1738, 1515, 1365, 1570, 1782, 1817, 1607, 1438, 1679, 1776, 1841, 1633, 1450, 1521, 1739, 1847, 1649, 1438, 1474, 1706, 1858, 1702, 1492, 1503, 1712, 1888, 1733, 1488, 1425, 1663, 1870, 1776, 1524, 1397, 1607, 1849, 1822, 1438, 1435, 1605, 1805, 1803, 1578, 1429, 1567, 1793, 1823, 1584, 1381, 1482, 1726, 1840, 1679, 1472, 1520, 1722, 1842, 1680, 1469, 1515, 1751, 1903, 1739, 1483, 1424, 1661, 1843, 1751, 1517, 1406, 1606, 1814, 1779, 1522, 1413, 1610, 1823, 1818, 1604, 1423, 1591, 1831, 1872, 1682, 1494, 1644, 1872, 1922, 1687, 1430, 1456, 1653, 1782, 1602, 1420, 1482, 1734, 1894, 1711, 1422, 1409, 1646, 1839, 1737, 1514, 1431, 1648, 1857, 1781, 1533, 1408, 1617, 1843, 1761, 1615, 1424, 1590, 1786, 1805, 1611, 1425, 1559, 1789, 1859, 1658, 1433, 1550, 1756, 1856, 1674, 1448, 1505, 1759, 1929, 1775, 1519, 1473, 1690, 1840, 1584, 1470, 1423, 1645, 1855, 1744, 1533, 1440, 1642, 1659, 1648, 1584, 1551, 1542, 1518, 1503, 1493, 1461, 1424, 1615, 1725, 1872, 1701, 1476, 1471, 1678, 1825, 1695, 1478, 1453, 1648, 1856, 1771, 1590, 1524, 1719, 1877, 1751, 1487, 1354, 1565, 1789, 1805, 1584, 1439, 1774, 1875, 1875, 1632, 1427, 1550, 1786, 1847, 1631, 1425, 1511, 1758, 1856, 1653, 1417, 1442, 1652, 1798, 1614, 1383, 1393, 1644, 1846, 1724, 1470, 1408, 1619, 1840, 1774, 1542, 1436, 1654, 1874, 1847, 1609, 1424, 1579, 1787, 1802, 1582, 1415, 1562, 1766, 1809, 1635, 1455, 1583, 1828, 1934, 1717, 1463, 1485, 1687, 1818, 1647, 1424, 1435, 1675, 1819, 1685, 1460, 1459, 1728, 1934, 1807, 1506, 1406, 1587, 1794, 1739, 1509, 1398, 1622, 1834, 1795, 1578, 1407, 1621, 1840, 1771, 1579, 1350, 1482, 1728, 1795, 1600, 1413, 1544, 1780, 1897, 1667, 1395, 1471, 1715, 1909, 1749, 1524, 1479, 1706, 1869, 1763, 1520, 1415, 1605, 1782, 1642, 1522, 1411, 1591, 1774, 1737, 1522, 1397, 1590, 1787, 1786, 1559, 1421, 1616, 1839, 1899, 1669, 1456, 1547, 1795, 1887, 1671, 1453, 1513, 1732, 1879, 1686, 1417, 1456, 1689, 1855, 1709, 1467, 1414, 1648, 1848, 1742, 1524, 1454, 1698, 1893, 1805, 1565, 1445, 1649, 1874, 1866, 1619, 1424, 1594, 1817, 1845, 1634, 1438, 1581, 1805, 1882, 1680, 1488, 1583, 1806, 1894, 1690, 1482, 1531, 1789, 1907, 1719, 1494, 1467, 1667, 1818, 1690, 1470, 1418, 1670, 1875, 1799, 1577, 1429, 1588, 1796, 1758, 1557, 1421, 1610, 1808, 1820, 1594, 1435, 1580, 1843, 1859, 1666, 1465, 1542, 1749, 1821, 1606, 1393, 1483, 1707, 1838, 1622, 1339, 1401, 1573, 1775, 1648, 1431, 1403, 1648, 1858, 1749, 1498, 1808, 1818, 1881, 1909, 1914, 1927, 1936, 1937, 1943, 1798, 1488, 1731, 1903, 1712, 1398, 1418, 1651, 1827, 1712, 1463, 1405, 1649, 1861, 1776, 1535, 1427, 1642, 1829, 1664, 1556, 1379, 1567, 1799, 1786, 1557, 1360, 1495, 1712, 1774, 1581, 1364, 1494, 1739, 1870, 1679, 1449, 1465, 1671, 1805, 1651, 1463, 1471, 1698, 1842, 1535, 1424, 1418, 1633, 1843, 1718, 1439, 1333, 1555, 1821, 1783, 1574, 1392, 1565, 1758, 1747, 1549, 1378, 1599, 1825, 1853, 1600, 1381, 1499, 1757, 1846, 1654, 1395, 1488, 1744, 1847, 1692, 1453, 1485, 1715, 1875, 1723, 1515, 1488, 1712, 1875, 1747, 1527, 1449, 1680, 1855, 1775, 1571, 1472, 1696, 1891, 1819, 1550, 1398, 1565, 1814, 1843, 1645, 1473, 1616, 1846, 1870, 1697, 1497, 1617, 1873, 1939, 1721, 1474, 1520, 1779, 1916, 1734, 1483, 1453, 1680, 1843, 1734, 1495, 1547, 1725, 1904, 1809, 1568, 1479, 1696, 1914, 1840, 1575, 1395, 1605, 1904, 1893, 1689, 1482, 1618, 1827, 1849, 1620, 1438, 1547, 1797, 1873, 1694, 1488, 1680, 1779, 1878, 1698, 1486, 1547, 1741, 1885, 1705, 1462, 1459, 1705, 1895, 1770, 1567, 1483, 1662, 1840, 1763, 1562, 1487, 1693, 1911, 1873, 1649, 1504, 1660, 1901, 1857, 1626, 1435, 1582, 1822, 1865, 1654, 1426, 1518, 1781, 1903, 1699, 1478, 1490, 1707, 1854, 1697, 1473, 1469, 1725, 1905, 1762, 1507, 1424, 1645, 1858, 1747, 1499, 1383, 1616, 1843, 1803, 1588, 1418, 1595, 1791, 1765, 1534, 1377, 1567, 1783, 1815, 1586, 1392, 1520, 1776, 1847, 1643, 1415, 1459, 1726, 1863, 1712, 1474, 1494, 1697, 1869, 1725, 1504, 1444, 1617, 1771, 1642, 1461, 1429, 1663, 1847, 1754, 1700, 1712, 1787, 1814, 1821, 1836, 1842, 1843, 1859, 1565, 1467, 1713, 1469, 1485, 1699, 1812, 1648, 1442, 1445, 1674, 1886, 1759, 1526, 1457, 1642, 1806, 1712, 1498, 1456, 1643, 1842, 1777, 1552, 1393, 1599, 1839, 1821, 1600, 1418, 1595, 1872, 1866, 1661, 1461, 1579, 1801, 1849, 1636, 1409, 1495, 1744, 1856, 1680, 1459, 1578, 1712, 1856, 1697, 1507, 1521, 1760, 1926, 1761, 1525, 1485, 1731, 1955, 1829, 1565, 1411, 1611, 1821, 1801, 1574, 1421, 1599, 1839, 1866, 1657, 1484, 1745, 1859, 1888, 1680, 1461, 1579, 1783, 1895, 1712, 1495, 1543, 1773, 1910, 1731, 1510, 1477, 1677, 1833, 1706, 1490, 1465, 1699, 1895, 1806, 1586, 1487, 1687, 1906, 1834, 1607, 1435, 1645, 1858, 1843, 1623, 1463, 1639, 1858, 1877, 1629, 1424, 1545, 1784, 1855, 1691, 1483, 1566, 1797, 1927, 1778, 1589, 1616, 1814, 1937, 1797, 1611, 1599, 1807, 1967, 1842, 1655, 1594, 1758, 1889, 1770, 1552, 1488, 1737, 1934, 1862, 1630, 1474, 1654, 1874, 1856, 1629, 1450, 1616, 1853, 1873, 1721, 1507, 1600, 1795, 1856, 1651, 1450, 1519, 1749, 1877, 1700, 1429, 1467, 1700, 1828, 1673, 1472, 1466, 1737, 1930, 1801, 1557, 1451, 1650, 1837, 1680, 1575, 1458, 1627, 1802, 1751, 1567, 1466, 1678, 1893, 1885, 1646, 1457, 1602, 1813, 1872, 1681, 1497, 1604, 1839, 1953, 1744, 1509, 1546, 1767, 1935, 1803, 1530, 1543, 1750, 1918, 1811, 1583, 1495, 1703, 1902, 1830, 1607, 1494, 1695, 1873, 1861, 1677, 1503, 1673, 1852, 1823, 1616, 1472, 1618, 1854, 1887, 1685, 1519, 1635, 1829, 1897, 1682, 1474, 1565, 1826, 1950, 1776, 1543, 1565, 1811, 1987, 1844, 1616, 1583, 1791, 1527, 1520, 1474, 1461, 1457, 1452, 1451, 1453, 1620, 1633, 1734, 1712, 1493, 1589, 1818, 1908, 1723, 1519, 1543, 1745, 1860, 1693, 1488, 1514, 1771, 1931, 1808, 1559, 1488, 1699, 1872, 1786, 1559, 1475, 1699, 1927, 1872, 1620, 1495, 1664, 1879, 1872, 1651, 1466, 1609, 1825, 1831, 1628, 1459, 1603, 1840, 1881, 1674, 1447, 1509, 1749, 1898, 1712, 1483, 1523, 1787, 1952, 1792, 1518, 1502, 1702, 1872, 1778, 1564, 1510, 1701, 1865, 1776, 1552, 1453, 1659, 1870, 1744, 1597, 1434, 1607, 1855, 1889, 1696, 1519, 1633, 1825, 1854, 1648, 1465, 1626, 1872, 1953, 1723, 1461, 1498, 1741, 1883, 1728, 1495, 1492, 1721, 1888, 1779, 1558, 1535, 1741, 1919, 1809, 1574, 1473, 1672, 1871, 1806, 1600, 1490, 1749, 1939, 1919, 1675, 1495, 1667, 1873, 1885, 1654, 1462, 1629, 1870, 1910, 1682, 1443, 1553, 1842, 1999, 1815, 1559, 1552, 1760, 1927, 1786, 1584, 1550, 1762, 1919, 1813, 1617, 1566, 1750, 1904, 1810, 1601, 1522, 1741, 1937, 1872, 1615, 1455, 1630, 1871, 1919, 1734, 1529, 1646, 1855, 1907, 1728, 1519, 1619, 1846, 1893, 1712, 1497, 1549, 1770, 1921, 1743, 1533, 1527, 1741, 1901, 1773, 1562, 1606, 1764, 1930, 1827, 1586, 1466, 1658, 1853, 1808, 1638, 1515, 1728, 1934, 1873, 1651, 1485, 1634, 1844, 1867, 1663, 1497, 1647, 1850, 1885, 1694, 1488, 1721, 1842, 1935, 1712, 1484, 1522, 1755, 1886, 1703, 1456, 1454, 1697, 1897, 1755, 1534, 1467, 1673, 1873, 1778, 1556, 1443, 1648, 1891, 1882, 1681, 1521, 1658, 1861, 1829, 1625, 1440, 1600, 1822, 1869, 1677, 1479, 1596, 1797, 1879, 1680, 1520, 1601, 1838, 1940, 1747, 1527, 1547, 1771, 1739, 1727, 1658, 1616, 1605, 1584, 1567, 1555, 1520, 1477, 1543, 1658, 1871, 1878, 1646, 1453, 1602, 1855, 1941, 1776, 1556, 1639, 1835, 1915, 1751, 1552, 1645, 1862, 2002, 1835, 1595, 1579, 1776, 1935, 1789, 1565, 1522, 1766, 1973, 1898, 1675, 1547, 1712, 1904, 1821, 1618, 1495, 1703, 1937, 1927, 1697, 1477, 1626, 1811, 1852, 1667, 1499, 1627, 1851, 1900, 1689, 1475, 1548, 1782, 1861, 1680, 1463, 1546, 1798, 1951, 1757, 1494, 1479, 1742, 1967, 1856, 1622, 1584, 1733, 1911, 1818, 1577, 1442, 1633, 1853, 1810, 1611, 1440, 1632, 1866, 1861, 1636, 1462, 1599, 1835, 1906, 1728, 1529, 1606, 1786, 1821, 1633, 1456, 1649, 1788, 1895, 1702, 1497, 1549, 1776, 1909, 1734, 1488, 1468, 1726, 1938, 1806, 1570, 1471, 1685, 1911, 1817, 1586, 1431, 1639, 1883, 1872, 1641, 1463, 1616, 1856, 1859, 1621, 1424, 1545, 1793, 1888, 1712, 1503, 1586, 1805, 1920, 1714, 1491, 1507, 1719, 1848, 1689, 1459, 1450, 1673, 1873, 1732, 1509, 1434, 1639, 1851, 1757, 1552, 1468, 1693, 1901, 1853, 1584, 1424, 1633, 1901, 1921, 1685, 1501, 1623, 1833, 1872, 1666, 1456, 1552, 1760, 1871, 1697, 1509, 1567, 1763, 1866, 1702, 1519, 1569, 1798, 1938, 1791, 1557, 1527, 1773, 1983, 1866, 1599, 1479, 1647, 1839, 1776, 1583, 1483, 1711, 1927, 1905, 1691, 1515, 1692, 1897, 1839, 1689, 1518, 1682, 1952, 2022, 1783, 1530, 1591, 1807, 1930, 1744, 1491, 1559, 1773, 1893, 1738, 1499, 1495, 1733, 1936, 1801, 1563, 1454, 1664, 1858, 1707, 1599, 1506, 1707, 1917, 1856, 1639, 1488, 1667, 1858, 1840, 1653, 1486, 1679, 1885, 1909, 1648, 1424, 1499, 1747, 1848, 1698, 1514, 1851, 1856, 1887, 1898, 1898, 1891, 1887, 1882, 1869, 1673, 1451, 1653, 1861, 1767, 1574, 1376, 1522, 1761, 1781, 1595, 1411, 1680, 1767, 1837, 1618, 1446, 1549, 1759, 1841, 1643, 1435, 1520, 1779, 1927, 1727, 1520, 1518, 1742, 1900, 1754, 1494, 1424, 1615, 1799, 1714, 1492, 1424, 1631, 1886, 1830, 1613, 1436, 1598, 1821, 1813, 1599, 1442, 1586, 1826, 1889, 1659, 1457, 1551, 1743, 1823, 1638, 1453, 1534, 1775, 1917, 1726, 1501, 1517, 1742, 1904, 1749, 1515, 1482, 1690, 1877, 1744, 1505, 1425, 1617, 1807, 1748, 1530, 1463, 1712, 1925, 1869, 1616, 1456, 1627, 1861, 1855, 1620, 1438, 1593, 1828, 1840, 1663, 1431, 1520, 1730, 1815, 1623, 1423, 1515, 1798, 1947, 1783, 1498, 1517, 1739, 1909, 1782, 1555, 1508, 1715, 1898, 1795, 1570, 1467, 1654, 1835, 1637, 1511, 1377, 1595, 1808, 1810, 1620, 1473, 1659, 1879, 1921, 1711, 1524, 1673, 1872, 1905, 1696, 1478, 1593, 1843, 1998, 1808, 1557, 1571, 1791, 1947, 1806, 1570, 1552, 1744, 1887, 1755, 1533, 1478, 1703, 1903, 1799, 1573, 1461, 1677, 1878, 1818, 1610, 1467, 1655, 1853, 1838, 1609, 1424, 1579, 1823, 1895, 1693, 1456, 1554, 1786, 1883, 1741, 1535, 1597, 1813, 1895, 1710, 1486, 1527, 1788, 1941, 1783, 1510, 1465, 1671, 1867, 1751, 1520, 1438, 1622, 1808, 1741, 1520, 1447, 1652, 1858, 1825, 1600, 1408, 1581, 1798, 1839, 1638, 1431, 1552, 1772, 1808, 1648, 1477, 1600, 1845, 1953, 1747, 1514, 1520, 1724, 1829, 1645, 1422, 1513, 1751, 1947, 1825, 1596, 1499, 1693, 1859, 1771, 1561, 1473, 1697, 1904, 1809, 1584, 1439, 1680, 1904, 1902, 1676, 1487, 1648, 1872, 1916, 1712, 1652, 1663, 1730, 1767, 1776, 1800, 1811, 1823, 1858, 1855, 1841, 1712, 1513, 1434, 1695, 1893, 1827, 1595, 1458, 1633, 1830, 1735, 1610, 1442, 1616, 1821, 1819, 1611, 1433, 1600, 1840, 1884, 1670, 1439, 1552, 1793, 1920, 1723, 1462, 1494, 1686, 1850, 1722, 1520, 1519, 1701, 1858, 1606, 1520, 1498, 1703, 1883, 1808, 1606, 1529, 1744, 1936, 1859, 1628, 1469, 1677, 1886, 1872, 1651, 1486, 1633, 1824, 1827, 1607, 1424, 1616, 1866, 1963, 1747, 1522, 1609, 1830, 1958, 1789, 1574, 1615, 1818, 1967, 1826, 1616, 1572, 1783, 1936, 1835, 1622, 1570, 1744, 1914, 1827, 1616, 1545, 1758, 1925, 1858, 1598, 1490, 1648, 1887, 1887, 1684, 1504, 1660, 1905, 1937, 1732, 1535, 1629, 1899, 1980, 1797, 1583, 1605, 1809, 1915, 1723, 1509, 1533, 1795, 1984, 1879, 1663, 1632, 1773, 1913, 1802, 1600, 1549, 1734, 1965, 1911, 1705, 1605, 1793, 2000, 1934, 1693, 1520, 1711, 1962, 1987, 1774, 1575, 1680, 1889, 1950, 1737, 1533, 1771, 1919, 2064, 1882, 1646, 1618, 1779, 1871, 1689, 1474, 1489, 1755, 1951, 1811, 1579, 1469, 1659, 1870, 1822, 1648, 1546, 1738, 1919, 1871, 1646, 1516, 1729, 1940, 1892, 1653, 1453, 1611, 1835, 1859, 1680, 1533, 1684, 1919, 1970, 1713, 1527, 1623, 1842, 1936, 1718, 1480, 1507, 1757, 1936, 1801, 1587, 1552, 1726, 1831, 1682, 1471, 1456, 1714, 1945, 1865, 1642, 1502, 1687, 1871, 1839, 1599, 1457, 1684, 1906, 1919, 1681, 1455, 1584, 1819, 1886, 1675, 1462, 1558, 1777, 1875, 1712, 1485, 1526, 1731, 1854, 1680, 1493, 1520, 1750, 1898, 1741, 1479, 1456, 1686, 1872, 1775, 1513, 1394, 1646, 1882, 1872, 1661, 1466, 1600, 1652, 1645, 1571, 1522, 1518, 1491, 1477, 1469, 1439, 1392, 1535, 1525, 1757, 1904, 1766, 1511, 1501, 1754, 1936, 1843, 1609, 1534, 1723, 1904, 1834, 1627, 1492, 1695, 1900, 1858, 1635, 1493, 1678, 1942, 1943, 1749, 1578, 1680, 1878, 1885, 1669, 1478, 1614, 1840, 1936, 1714, 1491, 1623, 1755, 1923, 1787, 1565, 1567, 1771, 1943, 1842, 1654, 1600, 1793, 1953, 1856, 1653, 1599, 1781, 1941, 1870, 1649, 1520, 1731, 1954, 1922, 1701, 1519, 1807, 1899, 1945, 1755, 1592, 1725, 1933, 1956, 1731, 1552, 1659, 1904, 1989, 1754, 1520, 1579, 1814, 1990, 1833, 1574, 1495, 1710, 1879, 1793, 1584, 1507, 1693, 1883, 1781, 1562, 1452, 1710, 1902, 1846, 1582, 1388, 1569, 1827, 1840, 1619, 1462, 1596, 1831, 1853, 1632, 1440, 1557, 1799, 1908, 1712, 1472, 1498, 1699, 1840, 1681, 1505, 1520, 1735, 1919, 1764, 1558, 1530, 1779, 1952, 1809, 1535, 1456, 1648, 1872, 1789, 1586, 1487, 1707, 1906, 1869, 1623, 1440, 1612, 1857, 1861, 1693, 1491, 1636, 1837, 1911, 1690, 1478, 1571, 1797, 1937, 1747, 1497, 1543, 1758, 1923, 1810, 1613, 1606, 1777, 1934, 1790, 1552, 1487, 1669, 1874, 1712, 1611, 1491, 1701, 1918, 1872, 1664, 1520, 1667, 1876, 1887, 1655, 1487, 1634, 1851, 1916, 1733, 1552, 1648, 1845, 1914, 1716, 1523, 1585, 1795, 1909, 1726, 1513, 1561, 1814, 1977, 1856, 1609, 1546, 1744, 1894, 1799, 1589, 1520, 1765, 1945, 1861, 1641, 1488, 1692, 1894, 1858, 1629, 1456, 1622, 1847, 1853, 1649, 1453, 1584, 1830, 1903, 1694, 1458, 1551, 1760, 1904, 1747, 1520, 1551, 1766, 1897, 1770, 1552, 1566, 1789, 1950, 1799, 1584, 1519, 1739, 1937, 1872, 1702, 1712, 1779, 1809, 1815, 1829, 1838, 1840, 1858, 1755, 1663, 1452, 1494, 1723, 1840, 1642, 1406, 1467, 1722, 1861, 1691, 1429, 1394, 1657, 1863, 1739, 1533, 1488, 1734, 1915, 1810, 1494, 1391, 1627, 1882, 1863, 1616, 1429, 1583, 1811, 1854, 1633, 1454, 1627, 1890, 1922, 1738, 1490, 1530, 1762, 1849, 1689, 1487, 1557, 1802, 1943, 1776, 1522, 1559, 1790, 1971, 1843, 1616, 1520, 1725, 1917, 1813, 1583, 1474, 1686, 1894, 1735, 1578, 1404, 1609, 1872, 1917, 1730, 1551, 1671, 1869, 1898, 1673, 1483, 1611, 1855, 1959, 1757, 1530, 1554, 1783, 1897, 1744, 1520, 1520, 1746, 1905, 1658, 1535, 1491, 1691, 1894, 1794, 1601, 1488, 1663, 1859, 1815, 1634, 1498, 1693, 1857, 1831, 1622, 1471, 1635, 1862, 1926, 1744, 1552, 1663, 1859, 1916, 1681, 1462, 1549, 1763, 1904, 1727, 1517, 1547, 1762, 1877, 1715, 1503, 1517, 1797, 1971, 1869, 1609, 1506, 1666, 1826, 1751, 1555, 1485, 1708, 1925, 1872, 1646, 1491, 1669, 1887, 1888, 1665, 1486, 1630, 1872, 1931, 1719, 1498, 1553, 1809, 1909, 1749, 1503, 1504, 1738, 1874, 1713, 1492, 1469, 1712, 1903, 1808, 1573, 1546, 1693, 1854, 1759, 1584, 1509, 1738, 1929, 1840, 1627, 1471, 1695, 1920, 1867, 1609, 1443, 1604, 1838, 1872, 1677, 1482, 1625, 1872, 1954, 1735, 1489, 1681, 1818, 1968, 1827, 1584, 1600, 1777, 1941, 1831, 1648, 1638, 1813, 1939, 1781, 1574, 1546, 1793, 1991, 1904, 1670, 1521, 1700, 1893, 1871, 1686, 1575, 1744, 1929, 1894, 1654, 1471, 1644, 1920, 1978, 1808, 1591, 1674, 1856, 1965, 1744, 1550, 1611, 1797, 1907, 1713, 1505, 1520, 1749, 1919, 1777, 1548, 1483, 1667, 1594, 1587, 1550, 1530, 1524, 1526, 1530, 1534, 1565, 1615, 1787, 1578, 1793, 1885, 1741, 1570, 1648, 1821, 1921, 1762, 1520, 1535, 1712, 1845, 1722, 1551, 1520, 1741, 1915, 1808, 1630, 1545, 1727, 1886, 1808, 1627, 1523, 1719, 1904, 1847, 1629, 1477, 1668, 1903, 1943, 1730, 1552, 1674, 1859, 1904, 1713, 1550, 1635, 1829, 1904, 1717, 1518, 1571, 1797, 1898, 1757, 1559, 1527, 1724, 1859, 1745, 1584, 1553, 1767, 1924, 1831, 1647, 1531, 1670, 1842, 1800, 1641, 1507, 1678, 1840, 1839, 1639, 1471, 1637, 1858, 1895, 1699, 1548, 1651, 1872, 1926, 1724, 1486, 1555, 1760, 1904, 1762, 1579, 1681, 1799, 1935, 1787, 1584, 1559, 1744, 1901, 1799, 1598, 1507, 1712, 1907, 1822, 1621, 1481, 1638, 1842, 1856, 1686, 1534, 1675, 1871, 1899, 1750, 1604, 1799, 1904, 1946, 1789, 1629, 1722, 1890, 1943, 1786, 1571, 1615, 1755, 1857, 1694, 1491, 1497, 1699, 1849, 1773, 1589, 1551, 1738, 1880, 1824, 1627, 1553, 1742, 1926, 1878, 1677, 1530, 1680, 1871, 1872, 1698, 1552, 1670, 1839, 1858, 1650, 1488, 1601, 1826, 1941, 1792, 1600, 1607, 1793, 1909, 1778, 1598, 1616, 1804, 1950, 1823, 1623, 1552, 1718, 1898, 1826, 1642, 1575, 1719, 1882, 1840, 1635, 1561, 1745, 1919, 1873, 1653, 1481, 1650, 1866, 1857, 1659, 1488, 1628, 1863, 1877, 1706, 1483, 1554, 1781, 1879, 1713, 1527, 1600, 1827, 1966, 1807, 1508, 1501, 1671, 1828, 1721, 1535, 1488, 1687, 1869, 1809, 1599, 1505, 1653, 1817, 1718, 1614, 1490, 1654, 1786, 1765, 1556, 1423, 1606, 1819, 1862, 1664, 1460, 1551, 1742, 1831, 1680, 1489, 1531, 1728, 1854, 1713, 1535, 1555, 1753, 1882, 1738, 1488, 1904, 1910, 1958, 1975, 1978, 1975, 1978, 1978, 1971, 1759, 1665, 1474, 1597, 1820, 1924, 1735, 1560, 1725, 1808, 1932, 1801, 1614, 1617, 1763, 1872, 1749, 1593, 1585, 1776, 1920, 1797, 1627, 1614, 1802, 1949, 1866, 1665, 1565, 1736, 1913, 1863, 1623, 1477, 1651, 1891, 1911, 1746, 1530, 1637, 1808, 1856, 1668, 1483, 1565, 1744, 1831, 1621, 1438, 1481, 1713, 1872, 1722, 1487, 1471, 1666, 1857, 1757, 1557, 1489, 1690, 1862, 1776, 1563, 1470, 1634, 1837, 1782, 1609, 1485, 1648, 1841, 1846, 1660, 1478, 1603, 1781, 1815, 1643, 1489, 1615, 1831, 1904, 1729, 1522, 1567, 1756, 1826, 1669, 1477, 1522, 1749, 1920, 1773, 1521, 1458, 1648, 1877, 1835, 1631, 1589, 1728, 1868, 1762, 1547, 1430, 1629, 1821, 1794, 1584, 1457, 1662, 1873, 1814, 1671, 1427, 1533, 1764, 1835, 1670, 1472, 1535, 1744, 1839, 1666, 1422, 1517, 1739, 1911, 1771, 1555, 1552, 1753, 1927, 1844, 1645, 1588, 1766, 1938, 1722, 1617, 1517, 1698, 1872, 1836, 1648, 1522, 1712, 1917, 1914, 1729, 1581, 1723, 1899, 1920, 1718, 1563, 1674, 1866, 1943, 1734, 1569, 1675, 1919, 2027, 1826, 1518, 1506, 1730, 1917, 1840, 1648, 1597, 1741, 1866, 1766, 1557, 1491, 1732, 1930, 1882, 1685, 1551, 1680, 1865, 1833, 1621, 1459, 1629, 1850, 1857, 1653, 1474, 1603, 1817, 1877, 1703, 1493, 1573, 1775, 1895, 1758, 1553, 1575, 1774, 1886, 1785, 1604, 1563, 1729, 1863, 1755, 1584, 1554, 1774, 1957, 1866, 1659, 1569, 1719, 1899, 1882, 1697, 1553, 1711, 1888, 1885, 1681, 1518, 1643, 1871, 1883, 1706, 1531, 1600, 1808, 1879, 1712, 1511, 1552, 1773, 1921, 1799, 1623, 1729, 1827, 1951, 1567, 1563, 1561, 1575, 1581, 1593, 1601, 1609, 1636, 1796, 1719, 1921, 1923, 1703, 1519, 1611, 1824, 1872, 1765, 1597, 1655, 1845, 1924, 1783, 1584, 1611, 1804, 1931, 1771, 1491, 1547, 1755, 1934, 1828, 1607, 1514, 1706, 1883, 1792, 1573, 1455, 1621, 1832, 1690, 1604, 1468, 1627, 1819, 1842, 1636, 1459, 1585, 1818, 1853, 1648, 1465, 1601, 1838, 1931, 1749, 1522, 1583, 1840, 2002, 1850, 1582, 1535, 1723, 1923, 1819, 1605, 1552, 1729, 1910, 1840, 1650, 1574, 1737, 1908, 1861, 1630, 1513, 1699, 1895, 1891, 1681, 1511, 1639, 1884, 1918, 1746, 1584, 1691, 1904, 1975, 1776, 1552, 1627, 1829, 1945, 1815, 1631, 1679, 1907, 2032, 1875, 1616, 1582, 1803, 1980, 1895, 1695, 1627, 1802, 1987, 1906, 1676, 1530, 1697, 1898, 1919, 1725, 1598, 1725, 1915, 1947, 1776, 1600, 1693, 1858, 1904, 1743, 1574, 1662, 1889, 1934, 1757, 1566, 1583, 1789, 1926, 1798, 1646, 1650, 1858, 2000, 1850, 1630, 1623, 1780, 1951, 1880, 1692, 1598, 1793, 1975, 1940, 1711, 1561, 1695, 1870, 1870, 1660, 1509, 1665, 1895, 1937, 1759, 1571, 1648, 1856, 1942, 1770, 1586, 1651, 1887, 1985, 1829, 1615, 1590, 1782, 1946, 1847, 1609, 1559, 1709, 1873, 1811, 1651, 1587, 1735, 1891, 1844, 1655, 1567, 1734, 1892, 1858, 1668, 1523, 1687, 1905, 1914, 1712, 1549, 1663, 1853, 1907, 1681, 1473, 1523, 1778, 1966, 1840, 1647, 1637, 1785, 1894, 1759, 1568, 1570, 1783, 1935, 1818, 1602, 1505, 1708, 1899, 1826, 1629, 1547, 1747, 1968, 1936, 1714, 1571, 1709, 1923, 1945, 1744, 1584, 1698, 1871, 1918, 1730, 1565, 1642, 1856, 1942, 1793, 1610, 1659, 1870, 1984, 1853, 1633, 1907, 1905, 1871, 1840, 1831, 1812, 1802, 1793, 1766, 1515, 1559, 1695, 1904, 1930, 1716, 1501, 1584, 1786, 1887, 1760, 1597, 1658, 1872, 2000, 1822, 1612, 1593, 1808, 1919, 1805, 1612, 1552, 1719, 1904, 1807, 1645, 1584, 1776, 1947, 1870, 1641, 1555, 1659, 1847, 1855, 1665, 1510, 1665, 1897, 1933, 1760, 1579, 1652, 1861, 1904, 1735, 1598, 1667, 1855, 1932, 1733, 1518, 1529, 1745, 1900, 1761, 1568, 1669, 1774, 1968, 1857, 1645, 1548, 1736, 1921, 1890, 1693, 1589, 1759, 1921, 1826, 1600, 1451, 1637, 1870, 1889, 1686, 1494, 1616, 1821, 1870, 1691, 1494, 1619, 1883, 1986, 1808, 1619, 1622, 1829, 1968, 1809, 1598, 1601, 1792, 1935, 1795, 1597, 1530, 1740, 1922, 1846, 1627, 1517, 1678, 1872, 1845, 1675, 1552, 1702, 1920, 1929, 1744, 1603, 1717, 1882, 1893, 1707, 1527, 1642, 1855, 1923, 1741, 1581, 1637, 1850, 1935, 1763, 1552, 1609, 1815, 1961, 1792, 1575, 1563, 1781, 1986, 1874, 1657, 1584, 1750, 1930, 1877, 1659, 1535, 1684, 1887, 1879, 1667, 1561, 1693, 1859, 1878, 1715, 1563, 1683, 1873, 1898, 1731, 1560, 1662, 1869, 1917, 1808, 1584, 1599, 1792, 1941, 1840, 1622, 1585, 1751, 1893, 1808, 1649, 1634, 1809, 1968, 1866, 1658, 1575, 1760, 2004, 1979, 1760, 1575, 1694, 1898, 1935, 1751, 1635, 1758, 1945, 1972, 1751, 1562, 1647, 1839, 1911, 1759, 1594, 1699, 1921, 2061, 1903, 1698, 1696, 1847, 1936, 1786, 1595, 1561, 1775, 1943, 1842, 1612, 1565, 1727, 1905, 1867, 1670, 1523, 1731, 1901, 1894, 1696, 1575, 1745, 1953, 1969, 1775, 1567, 1698, 1903, 1991, 1808, 1605, 1667, 1860, 1937, 1808, 1622, 1679, 1860, 1951, 1776, 1619, 1630, 1697, 1738, 1744, 1771, 1781, 1792, 1930, 1959, 1600, 1712, 1919, 1921, 1746, 1562, 1624, 1794, 1872, 1731, 1559, 1613, 1822, 1963, 1791, 1617, 1605, 1776, 1926, 1794, 1595, 1564, 1755, 1924, 1857, 1680, 1571, 1701, 1890, 1838, 1668, 1555, 1706, 1869, 1872, 1691, 1552, 1686, 1895, 1931, 1703, 1579, 1691, 1907, 1998, 1808, 1605, 1650, 1824, 1920, 1744, 1535, 1552, 1730, 1844, 1728, 1520, 1521, 1749, 1922, 1839, 1622, 1535, 1733, 1936, 1890, 1604, 1533, 1687, 1890, 1874, 1669, 1509, 1643, 1840, 1886, 1716, 1554, 1659, 1845, 1785, 1699, 1561, 1649, 1856, 1968, 1783, 1590, 1616, 1826, 1958, 1813, 1627, 1622, 1811, 2001, 1906, 1703, 1616, 1771, 1936, 1869, 1668, 1515, 1654, 1838, 1837, 1665, 1567, 1702, 1872, 1890, 1706, 1533, 1668, 1886, 1953, 1795, 1631, 1725, 1894, 1932, 1728, 1520, 1573, 1815, 1971, 1825, 1604, 1561, 1745, 1914, 1826, 1610, 1579, 1761, 1949, 1859, 1675, 1579, 1739, 1930, 1870, 1674, 1552, 1699, 1886, 1872, 1664, 1554, 1712, 1913, 1925, 1715, 1513, 1635, 1867, 1952, 1760, 1519, 1583, 1762, 1879, 1751, 1599, 1622, 1809, 1904, 1770, 1577, 1581, 1868, 2003, 1913, 1699, 1594, 1759, 1908, 1853, 1665, 1574, 1745, 1927, 1878, 1669, 1608, 1716, 1929, 1929, 1702, 1520, 1675, 1895, 1986, 1795, 1590, 1625, 1802, 1896, 1747, 1584, 1616, 1808, 1920, 1751, 1522, 1524, 1707, 1866, 1767, 1578, 1546, 1794, 1939, 1871, 1620, 1526, 1732, 1958, 1916, 1674, 1502, 1646, 1873, 1844, 1621, 1406, 1501, 1727, 1818, 1689, 1556, 1650, 1838, 1895, 1739, 1584, 1655, 1837, 1904, 1712, 1527, 1568, 1803, 1966, 1856, 1745, 1751, 1808, 1834, 1839, 1855, 1866, 1872, 1905, 1997, 1930, 1713, 1574, 1717, 1850, 1925, 1766, 1566, 1633, 1840, 1959, 1803, 1603, 1632, 1823, 2000, 1823, 1642, 1604, 1790, 1968, 1879, 1662, 1555, 1700, 1842, 1810, 1644, 1579, 1742, 1902, 1854, 1663, 1534, 1715, 1905, 1909, 1709, 1520, 1710, 1925, 2000, 1821, 1623, 1694, 1888, 1965, 1786, 1585, 1622, 1831, 1914, 1751, 1503, 1533, 1759, 1951, 1847, 1619, 1522, 1682, 1840, 1799, 1611, 1525, 1750, 1926, 1903, 1717, 1595, 1721, 1888, 1881, 1680, 1526, 1675, 1858, 1863, 1650, 1456, 1581, 1807, 1935, 1799, 1602, 1627, 1799, 1902, 1766, 1581, 1587, 1875, 1957, 1826, 1601, 1526, 1731, 1901, 1829, 1603, 1498, 1671, 1856, 1805, 1594, 1546, 1630, 1849, 1874, 1694, 1505, 1641, 1808, 1829, 1647, 1487, 1609, 1831, 1889, 1725, 1553, 1610, 1787, 1855, 1657, 1453, 1488, 1718, 1858, 1767, 1596, 1557, 1788, 1904, 1805, 1603, 1546, 1727, 1905, 1870, 1698, 1599, 1733, 1881, 1821, 1659, 1526, 1674, 1875, 1879, 1725, 1586, 1690, 1887, 1930, 1767, 1583, 1678, 1865, 1926, 1744, 1573, 1618, 1838, 1958, 1811, 1625, 1663, 1858, 1977, 1811, 1618, 1619, 1838, 1998, 1871, 1609, 1509, 1694, 1924, 1900, 1726, 1635, 1787, 1995, 1936, 1726, 1562, 1703, 1920, 1943, 1755, 1583, 1687, 1915, 2011, 1811, 1661, 1681, 1857, 1952, 1794, 1615, 1668, 1875, 2016, 1887, 1693, 1670, 1854, 2007, 1902, 1687, 1603, 1803, 2017, 1979, 1779, 1639, 1777, 1931, 1872, 1677, 1528, 1689, 1885, 1926, 1751, 1601, 1723, 1936, 1959, 1794, 1610, 1689, 1873, 1955, 1748, 1595, 1677, 1883, 2000, 1809, 1591, 1584, 1811, 1757, 1751, 1683, 1648, 1639, 1616, 1600, 1593, 1559, 1582, 1900, 1935, 1712, 1584, 1695, 1904, 1990, 1830, 1626, 1660, 1853, 1965, 1821, 1599, 1600, 1795, 1995, 1901, 1714, 1631, 1765, 1929, 1823, 1621, 1559, 1744, 1922, 1840, 1616, 1478, 1648, 1858, 1871, 1680, 1550, 1723, 1921, 1917, 1735, 1577, 1711, 1910, 1964, 1763, 1585, 1664, 1853, 1935, 1773, 1599, 1620, 1847, 1973, 1825, 1622, 1615, 1802, 1980, 1898, 1728, 1666, 1846, 2010, 1889, 1671, 1535, 1712, 1905, 1897, 1696, 1581, 1728, 1920, 1937, 1735, 1573, 1653, 1840, 1821, 1622, 1488, 1632, 1877, 1949, 1739, 1491, 1552, 1783, 1927, 1747, 1555, 1567, 1781, 1968, 1881, 1667, 1588, 1744, 1906, 1830, 1619, 1552, 1712, 1903, 1847, 1648, 1507, 1710, 1901, 1907, 1744, 1619, 1749, 1947, 1929, 1661, 1573, 1690, 1888, 1938, 1747, 1579, 1645, 1873, 1965, 1791, 1571, 1593, 1815, 1914, 1819, 1597, 1550, 1744, 1973, 1917, 1722, 1627, 1803, 1943, 1881, 1685, 1569, 1730, 1947, 1927, 1774, 1616, 1744, 1936, 1936, 1773, 1603, 1699, 1891, 1936, 1743, 1577, 1661, 1877, 2000, 1817, 1599, 1611, 1809, 1955, 1830, 1613, 1600, 1776, 1927, 1835, 1647, 1758, 1767, 1935, 1857, 1660, 1563, 1738, 1918, 1885, 1699, 1616, 1758, 1925, 1910, 1670, 1533, 1715, 1936, 2011, 1826, 1594, 1679, 1839, 1910, 1746, 1568, 1631, 1824, 1936, 1787, 1606, 1661, 1886, 1993, 1837, 1585, 1611, 1841, 2014, 1907, 1650, 1584, 1792, 2013, 2002, 1776, 1605, 1765, 1924, 1912, 1727, 1583, 1696, 1897, 1902, 1725, 1552, 1680, 1895, 1955, 1774, 1595, 1680, 1887, 2018, 1855, 1673, 1693, 1886, 1990, 1829, 1611, 1591, 1962, 1957, 1903, 1861, 1851, 1824, 1808, 1799, 1747, 1535, 1619, 1904, 1913, 1763, 1600, 1666, 1827, 1913, 1696, 1567, 1613, 1806, 1930, 1790, 1604, 1605, 1798, 1967, 1881, 1685, 1632, 1777, 1895, 1826, 1638, 1584, 1787, 1993, 1969, 1773, 1585, 1695, 1867, 1859, 1697, 1565, 1686, 1863, 1863, 1712, 1552, 1669, 1871, 1907, 1754, 1574, 1616, 1811, 1902, 1738, 1600, 1621, 1830, 1939, 1794, 1600, 1570, 1754, 1883, 1787, 1606, 1600, 1776, 1968, 1877, 1670, 1552, 1728, 1918, 1900, 1690, 1522, 1654, 1847, 1897, 1714, 1632, 1742, 1930, 1947, 1757, 1582, 1676, 1936, 2037, 1872, 1623, 1641, 1839, 2000, 1880, 1654, 1579, 1724, 1864, 1747, 1579, 1534, 1739, 1910, 1853, 1634, 1558, 1727, 1905, 1878, 1694, 1606, 1751, 1918, 1899, 1678, 1518, 1702, 1888, 1939, 1774, 1583, 1655, 1838, 1917, 1789, 1615, 1664, 1824, 1909, 1744, 1554, 1633, 1840, 2019, 1915, 1678, 1621, 1776, 1939, 1859, 1671, 1614, 1867, 1985, 1930, 1723, 1597, 1745, 1903, 1893, 1697, 1559, 1699, 1904, 1904, 1723, 1556, 1638, 1803, 1871, 1723, 1578, 1687, 1892, 1968, 1763, 1559, 1605, 1814, 1947, 1803, 1589, 1563, 1771, 1940, 1861, 1680, 1628, 1782, 1921, 1803, 1593, 1498, 1727, 1920, 1907, 1714, 1578, 1715, 1886, 1873, 1669, 1528, 1649, 1873, 1936, 1735, 1552, 1616, 1827, 1918, 1775, 1593, 1620, 1793, 1915, 1776, 1602, 1619, 1810, 1887, 1735, 1530, 1519, 1738, 1899, 1815, 1605, 1489, 1682, 1873, 1850, 1694, 1584, 1723, 1920, 1897, 1713, 1565, 1701, 1911, 1947, 1797, 1623, 1711, 1941, 1953, 1769, 1590, 1645, 1859, 1971, 1824, 1599, 1598, 1794, 1946, 1761, 1631, 1936, 1946, 2000, 2018, 2023, 2030, 2032, 2032, 2029, 1847, 1521, 1631, 1845, 1907, 1750, 1565, 1664, 1821, 1948, 1808, 1619, 1648, 1808, 1936, 1811, 1661, 1657, 1847, 1955, 1797, 1593, 1552, 1734, 1911, 1856, 1675, 1607, 1762, 1927, 1871, 1681, 1575, 1771, 1883, 1853, 1638, 1509, 1664, 1886, 1920, 1739, 1571, 1647, 1870, 1931, 1754, 1559, 1626, 1819, 1907, 1744, 1553, 1569, 1808, 1977, 1854, 1627, 1584, 1757, 1946, 1861, 1665, 1598, 1735, 1908, 1817, 1629, 1513, 1717, 1967, 1991, 1810, 1643, 1744, 1872, 1885, 1724, 1589, 1727, 1941, 1983, 1805, 1619, 1705, 1910, 2021, 1882, 1680, 1698, 1861, 1969, 1811, 1639, 1635, 1824, 1953, 1812, 1600, 1569, 1797, 1962, 1903, 1686, 1564, 1703, 1878, 1863, 1685, 1589, 1746, 1947, 1902, 1715, 1559, 1725, 1933, 1952, 1744, 1552, 1622, 1826, 1919, 1761, 1609, 1681, 1856, 1914, 1769, 1583, 1639, 1858, 2015, 1885, 1646, 1591, 1734, 1904, 1810, 1656, 1616, 1761, 1916, 1830, 1610, 1522, 1731, 1962, 1943, 1750, 1573, 1713, 1977, 1956, 1769, 1591, 1680, 1852, 1866, 1707, 1523, 1680, 1922, 2041, 1789, 1623, 1656, 1876, 2032, 1891, 1664, 1637, 1823, 1973, 1873, 1695, 1655, 1859, 2013, 1909, 1712, 1615, 1763, 1935, 1883, 1681, 1575, 1711, 1923, 1907, 1721, 1531, 1649, 1830, 1869, 1699, 1510, 1632, 1841, 1926, 1799, 1621, 1673, 1872, 1989, 1837, 1669, 1675, 1885, 2007, 1883, 1665, 1601, 1755, 1917, 1817, 1635, 1597, 1767, 1951, 1877, 1691, 1564, 1692, 1854, 1792, 1601, 1472, 1647, 1872, 1911, 1723, 1567, 1650, 1837, 1903, 1743, 1557, 1616, 1788, 1887, 1730, 1546, 1551, 1743, 1891, 1782, 1728, 1735, 1783, 1810, 1817, 1840, 1852, 1860, 1894, 1962, 1691, 1767, 1922, 1922, 1778, 1644, 1778, 1959, 2002, 1790, 1603, 1651, 1855, 1968, 1797, 1616, 1680, 1940, 2034, 1879, 1677, 1657, 1878, 2096, 1975, 1746, 1648, 1815, 2000, 1953, 1776, 1629, 1776, 1941, 1901, 1727, 1583, 1696, 1904, 1922, 1731, 1535, 1662, 1949, 1979, 1817, 1610, 1651, 1847, 1968, 1827, 1632, 1657, 1861, 2001, 1808, 1639, 1617, 1776, 1935, 1809, 1591, 1521, 1712, 1907, 1853, 1670, 1563, 1766, 2001, 1963, 1745, 1567, 1712, 1948, 1936, 1747, 1573, 1681, 1904, 1961, 1784, 1599, 1650, 1845, 1902, 1722, 1543, 1599, 1818, 1939, 1808, 1597, 1610, 1805, 1966, 1790, 1583, 1507, 1732, 1947, 1906, 1695, 1603, 1776, 1965, 1894, 1677, 1523, 1666, 1872, 1893, 1744, 1622, 1774, 1969, 1957, 1750, 1583, 1665, 1874, 1936, 1729, 1572, 1623, 1826, 1931, 1819, 1619, 1648, 1821, 1967, 1849, 1650, 1646, 1798, 1957, 1857, 1667, 1611, 1826, 2003, 1933, 1706, 1584, 1737, 1904, 1885, 1662, 1599, 1743, 1923, 1892, 1701, 1569, 1728, 1941, 1983, 1739, 1506, 1608, 1805, 1958, 1855, 1679, 1711, 1861, 1959, 1761, 1571, 1585, 1804, 1947, 1803, 1509, 1561, 1783, 1996, 1906, 1694, 1595, 1765, 1962, 1947, 1776, 1675, 1879, 1989, 1952, 1753, 1618, 1787, 2003, 2012, 1803, 1637, 1723, 1937, 1994, 1835, 1659, 1744, 1937, 2035, 1881, 1706, 1702, 1895, 2011, 1891, 1710, 1712, 1863, 1983, 1861, 1698, 1663, 1836, 1977, 1866, 1648, 1565, 1771, 1979, 1943, 1755, 1579, 1756, 1927, 1935, 1741, 1584, 1706, 1913, 1984, 1803, 1630, 1702, 1891, 1979, 1820, 1630, 1707, 1897, 2009, 1567, 1564, 1571, 1589, 1597, 1611, 1617, 1623, 1662, 1910, 1951]\n",
    "\n",
    "print(min(test),max(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try TRCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eeg_lib.trca import TRCA_SSVEP\n",
    "\n",
    "list_freq = [7,10,12]\n",
    "trca = TRCA_SSVEP(list_freq)\n",
    "number_of_train  = 4\n",
    "\n",
    "# data_packed = np.array([values_7, values_10, values_12])\n",
    "train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "train = data_packed[:,:,:,train_test_idxs[0][1]]\n",
    "test = data_packed[:,:,:,train_test_idxs[0][0]]\n",
    "\n",
    "trca.fit(train)\n",
    "\n",
    "results= {7:0,10:0,12:0}\n",
    "for freq in range(3):\n",
    "    for test_idx in range(test.shape[-1]):\n",
    "        test_now = test[freq, :, :, test_idx]\n",
    "        res = trca.compute_corr(test_now)\n",
    "        for key, prob in res.items():\n",
    "            res[key] = abs(prob)\n",
    "        max_res = max(res, key=res.get)\n",
    "        if max_res == list_freq[freq]:\n",
    "            results[max_res]+=1\n",
    "        print('freq:',freq,max_res)\n",
    "\n",
    "print(test.shape[-1])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c2c8e20dc0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_file_7 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\decreased_noise_location\\7.txt\")\n",
    "plt.plot(data_file_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c2c8ee1580>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_file_7 = load_array_data(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\Proper_Gain_255\\7hz_2.txt\")\n",
    "plt.plot(data_file_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
