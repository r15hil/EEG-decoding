{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from sklearn.model_selection import LeavePOut\n",
    "import random\n",
    "from eeg_lib.cca import GCCA_SSVEP\n",
    "from eeg_lib.cca import MsetCCA_SSVEP\n",
    "from eeg_lib.utils import standardise\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def synth_x(f, Ns, noise_power=0.5, fs=256):\n",
    "    t = np.arange(0, Ns/fs, 1/fs)\n",
    "    return np.sin(t*2*np.pi*f)*(1+random.random()*noise_power)\n",
    "\n",
    "SOS_SSVEP_BANDPASS_256HZ = np.array(\n",
    "    [   [5.18442631e-04, 5.91022291e-04, 5.18442631e-04, 1.00000000e00, -1.58700686e00, 6.47826110e-01,],\n",
    "        [1.00000000e00, -6.71721317e-01, 1.00000000e00, 1.00000000e00, -1.56164716e00, 7.42956116e-01,],\n",
    "        [1.00000000e00, -1.19862825e00, 1.00000000e00, 1.00000000e00, -1.53434369e00, 8.53024717e-01,],\n",
    "        [1.00000000e00, -1.36462221e00, 1.00000000e00, 1.00000000e00, -1.52074686e00, 9.31086238e-01,],\n",
    "        [1.00000000e00, -1.41821305e00, 1.00000000e00, 1.00000000e00, -1.52570664e00, 9.80264626e-01,],\n",
    "    ])\n",
    "\n",
    "fs_openbci = 200\n",
    "filt_ord = 10\n",
    "pb_rip = 0.2\n",
    "sb_atten = 80\n",
    "\n",
    "fc_lo = 4 # pass band lower freq\n",
    "fc_hi = 28 # pass band upp freq \n",
    "wc_lo = fc_lo/(fs_openbci*0.5)\n",
    "wc_hi = fc_hi/(fs_openbci*0.5)\n",
    "\n",
    "sos_openbci = signal.ellip(filt_ord, pb_rip, sb_atten, (wc_lo, wc_hi), btype='bandpass', output='sos')\n",
    "\n",
    "def load_array_data(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(', ')\n",
    "    for i, v in enumerate(data_file):\n",
    "        if '[' in v:\n",
    "            data_file[i] = v.replace('[','')\n",
    "        if ']\\n' in v:\n",
    "            data_file[i] = v.replace(']\\n','')\n",
    "            \n",
    "    values = [int(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def load_array_data_float(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(', ')\n",
    "    for i, v in enumerate(data_file):\n",
    "        if '[' in v:\n",
    "            data_file[i] = v.replace('[','')\n",
    "        if ']\\n' in v:\n",
    "            data_file[i] = v.replace(']\\n','')\n",
    "            \n",
    "    values = [float(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def load_array_data_online(file_path):\n",
    "    data_file = open(file_path, \"r\")\n",
    "    data_file = data_file.read().split(',')            \n",
    "    values = [float(i) for i in data_file]\n",
    "    return values\n",
    "\n",
    "def average_every_n(values, size):\n",
    "#     return np.array([sum(group) / size for group in zip(*[iter(values)]*size)])\n",
    "    return values[::size]\n",
    "\n",
    "def sos_filter_OpenBCI(values):\n",
    "    return signal.sosfilt(sos_openbci, values)\n",
    "\n",
    "def sos_filter_256(values):\n",
    "    return signal.sosfilt(SOS_SSVEP_BANDPASS_256HZ, values)\n",
    "\n",
    "def process_data(data, no_samples, no_train, remove_DC=True, apply_filter=False, ds_rate=1, downsample=False):\n",
    "\n",
    "    data = data[:int(len(data)/no_samples)*no_samples]\n",
    "    \n",
    "    if remove_DC:\n",
    "        data = data - sum(data)/len(data)\n",
    "        if apply_filter:\n",
    "            data = sos_filter_256(data)[no_samples:]\n",
    "            plt.plot(data[:256])\n",
    "            \n",
    "    if downsample:\n",
    "        print(\"downsampling\",len(data))\n",
    "        data = average_every_n(data, ds_rate)\n",
    "        print(\"to\",len(data))\n",
    "        data = data[:int(len(data)/no_samples)*no_samples]\n",
    "        \n",
    "    data_reshape = data.reshape(int(len(data)/no_samples),no_samples)\n",
    "    data = data_reshape.T.reshape(1,no_samples,int(len(data)/no_samples))\n",
    "    return np.array(data)\n",
    "\n",
    "def process_data_OpenBCI(data, no_samples, no_train, remove_DC=True, apply_filter=False, ds_rate=1, downsample=False):\n",
    "\n",
    "    data = data[:int(len(data)/no_samples)*no_samples]\n",
    "    \n",
    "    if remove_DC:\n",
    "        data = data - sum(data)/len(data)\n",
    "        if apply_filter:\n",
    "            data = sos_filter_OpenBCI(data)[no_samples:]\n",
    "            plt.plot(data[:256])\n",
    "            \n",
    "    if downsample:\n",
    "        print(\"downsampling\",len(data))\n",
    "        data = average_every_n(data, ds_rate)\n",
    "        print(\"to\",len(data))\n",
    "        data = data[:int(len(data)/no_samples)*no_samples]\n",
    "        \n",
    "    data_reshape = data.reshape(int(len(data)/no_samples),no_samples)\n",
    "    data = data_reshape.T.reshape(1,no_samples,int(len(data)/no_samples))\n",
    "    return np.array(data)\n",
    "\n",
    "def prepare_data(data, frequency, fs, fs_synth, no_samples, no_train, remove_DC=True, apply_filter=True, downsample=False, ds_avg=1, synth_power=0, noise_power=0):\n",
    "    data = data + synth_power*synth_x(frequency, len(data), noise_power=0, fs=fs_synth)\n",
    "    values = process_data(data,no_samples,no_train,remove_DC=remove_DC,apply_filter=apply_filter,ds_rate=ds_avg,downsample=downsample)\n",
    "    return values\n",
    "\n",
    "def prepare_data_OpenBCI(data, frequency, fs, fs_synth, no_samples, no_train, remove_DC=True, apply_filter=True, downsample=False, ds_avg=1, synth_power=0, noise_power=0):\n",
    "    data = data + synth_power*synth_x(frequency, len(data), noise_power=0, fs=fs_synth)\n",
    "    values = process_data_OpenBCI(data,no_samples,no_train,remove_DC=remove_DC,apply_filter=apply_filter,ds_rate=ds_avg,downsample=downsample)\n",
    "    return values\n",
    "\n",
    "def generate_train_test_idxs(data,no_train):\n",
    "    lpo = LeavePOut(p=no_train)\n",
    "    no_trials = data.shape[-1]\n",
    "    return list(lpo.split(range(no_trials)))\n",
    "\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def test_gcca_mset(data, data_idxs, freqs, fs, no_samples, number_runs=10):\n",
    "    # Nf x Nc x Ns x Nt\n",
    "    gcca = GCCA_SSVEP(freqs, fs, Nh=1)\n",
    "    mset_cca = MsetCCA_SSVEP(freqs)\n",
    "    gcca_total_acc = []\n",
    "    mset_total_acc = []\n",
    "    gcca_freq_acc = dict((key,[]) for key in freqs)\n",
    "    mset_freq_acc = dict((key,[]) for key in freqs)\n",
    "\n",
    "    for i in range(number_runs):\n",
    "        # Nf x Nc x Ns x Nt\n",
    "        train = data[:,:,:,data_idxs[i][1]]\n",
    "        test = data[:,:,:,data_idxs[i][0]]\n",
    "\n",
    "        gcca.fit(train)\n",
    "        mset_cca.fit(train)\n",
    "        \n",
    "        for freq, value in enumerate(freqs):\n",
    "            gcca_res = []\n",
    "            mset_res = []\n",
    "            #print(\"############################# Frequency:\", value, \" #############################\")\n",
    "            for test_idx in range(test.shape[-1]):\n",
    "                test_now = test[freq, :, :, test_idx]\n",
    "                \n",
    "                gcca_decode = gcca.classify(test_now)\n",
    "#                 print(gcca_decode)\n",
    "                for key, prob in gcca_decode.items():\n",
    "                    gcca_decode[key] = abs(prob)\n",
    "                \n",
    "                gcca_res.append(max(gcca_decode, key=gcca_decode.get))\n",
    "                \n",
    "                mset_decode = mset_cca.classify(test_now)\n",
    "#                 print(mset_decode)\n",
    "                mset_res.append(max(mset_decode, key=mset_decode.get))\n",
    "            #print(\"GCCA accuracy {gcca_acc}\\nMsetCCA {mset_acc}\".format(gcca_acc=gcca_res.count(value)/len(gcca_res),mset_acc=mset_res.count(value)/len(mset_res)))\n",
    "            \n",
    "            gcca_total_acc.append(gcca_res.count(value)/len(gcca_res))\n",
    "            mset_total_acc.append(mset_res.count(value)/len(mset_res))\n",
    "            gcca_freq_acc[value].append(gcca_res)\n",
    "            mset_freq_acc[value].append(mset_res)\n",
    "    \n",
    "    total_gcca = sum(gcca_total_acc)/len(gcca_total_acc)\n",
    "    print(\"GCCA Total Average Accuracy:\", sum(gcca_total_acc)/len(gcca_total_acc))\n",
    "    total_mset = sum(mset_total_acc)/len(mset_total_acc)\n",
    "    print(\"MsetCCA Total Average Accuracy:\", sum(mset_total_acc)/len(mset_total_acc))\n",
    "    \n",
    "    gcca_freq_scores = []\n",
    "    mset_freq_scores = []\n",
    "    \n",
    "    for key, value in gcca_freq_acc.items():\n",
    "        flattened = flatten(value)\n",
    "        print(\"GCCA {frequency}hz accuracy:{result}\".format(frequency=key, result=flattened.count(key)/len(flattened)))\n",
    "        gcca_freq_scores.append(flattened.count(key)/len(flattened))\n",
    "    for key, value in mset_freq_acc.items():\n",
    "        flattened = flatten(value)\n",
    "        print(\"MsetCCA {frequency}hz accuracy:{result}\".format(frequency=key, result=flattened.count(key)/len(flattened)))\n",
    "        mset_freq_scores.append(flattened.count(key)/len(flattened))\n",
    "        \n",
    "    return total_gcca, total_mset, gcca_freq_scores, mset_freq_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "(1, 250, 30) (1, 250, 30) (1, 250, 30)\n",
      "(3, 1, 250, 30)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "ds = 1 #downsample averaging size\n",
    "if ds > 1:\n",
    "    downsample=True\n",
    "else:\n",
    "    downsample=False\n",
    "freqs = [8,10,12]\n",
    "fs_synth = 250\n",
    "fs = int(fs_synth/ds)\n",
    "over_n_seconds = 1\n",
    "number_of_samples = fs*over_n_seconds\n",
    "number_of_train = 8\n",
    "removeDC = False\n",
    "applyFilter = False\n",
    "synth_power = 0\n",
    "synth_noise = 0\n",
    "\n",
    "gcca_arr = {}\n",
    "mset_arr = {}\n",
    "gcca_f = {'Pz':[], 'PO5':[], 'PO3':[], 'POz':[], 'PO4':[], 'PO6':[], 'O1':[], 'Oz':[], 'O2':[]}\n",
    "mset_f = {'Pz':[], 'PO5':[], 'PO3':[], 'POz':[], 'PO4':[], 'PO6':[], 'O1':[], 'Oz':[], 'O2':[]}\n",
    "\n",
    "blocks = [i for i in range(1,7)]\n",
    "channel_locations = ['Pz', 'PO5', 'PO3', 'POz', 'PO4', 'PO6', 'O1', 'Oz', 'O2']\n",
    "\n",
    "print(blocks)\n",
    "for channel in range(1,10):\n",
    "    data_file_7 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        data_file_7 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/8hz/8hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "#         data_file_7 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\8hz\\8hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "\n",
    "    values_7 = prepare_data(data_file_7, 8, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample, ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    data_file_10 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        data_file_10 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/10hz/10hz_channel_0{c}_0{b}\".format(c=channel,b=block))\n",
    "#         data_file_10 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\10hz\\10hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "\n",
    "    values_10 = prepare_data(data_file_10, 10, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    data_file_12 = []\n",
    "#     for block in range(1,7):\n",
    "    for block in blocks:\n",
    "        data_file_12 += load_array_data_online(\"/Users/rishil/Desktop/FYP/EEG-decoding/eeg_lib/log/mnakanishi/12hz/12hz_channel_0{c}_0{b}\".format(c=channel,b=block))\n",
    "#         data_file_12 += load_array_data_online(r\"C:\\Users\\RISHI\\Desktop\\FYP\\EEG-decoding\\eeg_lib\\log\\mnakanishi\\12hz\\12hz_channel_0{c}_0{b}\".format(c=channel,b=block))                                       \n",
    "    values_12 = prepare_data(data_file_12, 12, fs, fs_synth, number_of_samples, number_of_train, remove_DC=removeDC, apply_filter=applyFilter, downsample=downsample,ds_avg=ds, synth_power=synth_power, noise_power=synth_noise)\n",
    "\n",
    "    print(values_12.shape, values_10.shape, values_7.shape)\n",
    "\n",
    "    data_packed = np.array([values_7, values_10, values_12])\n",
    "\n",
    "    print(data_packed.shape)\n",
    "\n",
    "    train_test_idxs = generate_train_test_idxs(data_packed, number_of_train)\n",
    "    print(len(train_test_idxs))\n",
    "    print((train_test_idxs[0]))\n",
    "    gcca, mset, gccaf, msetf = test_gcca_mset(data_packed, train_test_idxs, freqs, fs, number_of_samples, number_runs=1)\n",
    "    gcca_arr[channel_locations[channel-1]] = gcca\n",
    "    mset_arr[channel_locations[channel-1]] = mset\n",
    "    gcca_f[channel_locations[channel-1]].append(gccaf)\n",
    "    mset_f[channel_locations[channel-1]].append(msetf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCCA: {\n",
      "    \"O1\": 0.6388888888888888,\n",
      "    \"O2\": 0.5972222222222222,\n",
      "    \"Oz\": 0.6805555555555557,\n",
      "    \"PO3\": 0.6249999999999999,\n",
      "    \"PO4\": 0.5833333333333334,\n",
      "    \"PO5\": 0.625,\n",
      "    \"PO6\": 0.48611111111111116,\n",
      "    \"POz\": 0.6944444444444445,\n",
      "    \"Pz\": 0.48611111111111116\n",
      "}\n",
      "MsetCCA: {\n",
      "    \"O1\": 0.6805555555555555,\n",
      "    \"O2\": 0.5694444444444444,\n",
      "    \"Oz\": 0.8333333333333334,\n",
      "    \"PO3\": 0.625,\n",
      "    \"PO4\": 0.5694444444444445,\n",
      "    \"PO5\": 0.6111111111111112,\n",
      "    \"PO6\": 0.4583333333333333,\n",
      "    \"POz\": 0.7361111111111112,\n",
      "    \"Pz\": 0.5\n",
      "}\n",
      "GCCA Frequencies: {'Pz': [[0.4166666666666667, 0.625, 0.4166666666666667]], 'PO5': [[0.75, 0.625, 0.5]], 'PO3': [[0.75, 0.6666666666666666, 0.4583333333333333]], 'POz': [[0.9583333333333334, 0.7083333333333334, 0.4166666666666667]], 'PO4': [[0.7083333333333334, 0.5833333333333334, 0.4583333333333333]], 'PO6': [[0.2916666666666667, 0.5, 0.6666666666666666]], 'O1': [[0.7916666666666666, 0.5833333333333334, 0.5416666666666666]], 'Oz': [[0.9583333333333334, 0.75, 0.3333333333333333]], 'O2': [[0.6666666666666666, 0.7083333333333334, 0.4166666666666667]]}\n",
      "MsetCCA Frequencies: {'Pz': [[0.5416666666666666, 0.5416666666666666, 0.4166666666666667]], 'PO5': [[0.5833333333333334, 0.5833333333333334, 0.6666666666666666]], 'PO3': [[0.5833333333333334, 0.625, 0.6666666666666666]], 'POz': [[0.75, 0.75, 0.7083333333333334]], 'PO4': [[0.4583333333333333, 0.6666666666666666, 0.5833333333333334]], 'PO6': [[0.2916666666666667, 0.4583333333333333, 0.625]], 'O1': [[0.6666666666666666, 0.6666666666666666, 0.7083333333333334]], 'Oz': [[0.8333333333333334, 0.8333333333333334, 0.8333333333333334]], 'O2': [[0.5416666666666666, 0.5416666666666666, 0.625]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"GCCA:\", json.dumps(gcca_arr, indent=4, sort_keys=True))\n",
    "print(\"MsetCCA:\", json.dumps(mset_arr, indent=4, sort_keys=True))\n",
    "\n",
    "print(\"GCCA Frequencies:\", gcca_f)\n",
    "print(\"MsetCCA Frequencies:\", mset_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
